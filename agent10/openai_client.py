# agent10/openai_client.py
import os
import time

try:
    from openai import OpenAI
except Exception:
    OpenAI = None


class OpenAIChatCompletionClient:
    """
    OpenAI ChatCompletion Client (Ollama ì™„ì „ ì°¨ë‹¨ + ë¼ìš°íŒ… ë””ë²„ê·¸)

    - ëª¨ë¸: gpt-4o-mini
    - base_url: https://api.openai.com/v1 (ê°•ì œ)
    - OPENAI_OFFLINE=1 ì´ë©´ ë”ë¯¸ ì‘ë‹µ
    - Ollama / localhost / ë¡œì»¬ LLM ê²½ë¡œ ì™„ì „ ì°¨ë‹¨
    - í•­ìƒ str ë°˜í™˜
    """

    def __init__(self, model="gpt-4o-mini"):
        # -------------------------------------------------
        # ğŸ”¥ Ollama ê´€ë ¨ í™˜ê²½ë³€ìˆ˜ ì™„ì „ ì œê±°
        # -------------------------------------------------
        for k in [
            "OLLAMA_BASE_URL",
            "OLLAMA_HOST",
            "DISABLE_OLLAMA",
            "LOCAL_LLM",
            "LLM_PROVIDER",
        ]:
            os.environ.pop(k, None)

        self.model = model
        self.api_key = os.getenv("OPENAI_API_KEY")
        self.offline = os.getenv("OPENAI_OFFLINE", "0") == "1"

        self.base_url = "https://api.openai.com/v1"
        self.provider = "openai"

        self.client = None

        if self.offline:
            print("[OpenAIClient] OPENAI_OFFLINE=1 -> OFFLINE mode")
            return

        if not self.api_key:
            print("[OpenAIClient] OPENAI_API_KEY not found -> OFFLINE mode")
            self.offline = True
            return

        if OpenAI is None:
            print("[OpenAIClient] openai package not available -> OFFLINE mode")
            self.offline = True
            return

        try:
            # âœ… base_url ê°•ì œ ì§€ì •
            self.client = OpenAI(
                api_key=self.api_key,
                base_url=self.base_url,
            )
        except Exception as e:
            print(f"[OpenAIClient] OpenAI init failed: {e}")
            self.offline = True
            self.client = None

    # -------------------------------------------------
    # utils
    # -------------------------------------------------
    def _dummy_response(self):
        return (
            "TITLE: [ì˜¤í”„ë¼ì¸ ëª¨ë“œ]\n"
            "BODY: OPENAI_API_KEYê°€ ì—†ê±°ë‚˜ OpenAI í˜¸ì¶œì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        )

    # -------------------------------------------------
    # main
    # -------------------------------------------------
    def chat(self, messages, temperature=0.7):
        """
        messages: [{"role": "system"|"user"|"assistant", "content": "..."}]
        return: str
        """

        # ğŸ”¥ ì‹¤ì œ í˜¸ì¶œ ì§ì „ ë¼ìš°íŒ… ë””ë²„ê·¸ (íŒë³„ìš© í•µì‹¬ ë¡œê·¸)
        print(
            "[LLM ROUTE DEBUG]",
            "provider=", self.provider,
            "model=", self.model,
            "base_url=", self.base_url,
            "OPENAI_OFFLINE=", os.getenv("OPENAI_OFFLINE"),
            "OLLAMA_BASE_URL=", os.getenv("OLLAMA_BASE_URL"),
        )

        if self.offline or not self.client:
            return self._dummy_response()

        if not messages:
            return self._dummy_response()

        max_attempts = 3
        backoff = 1.5

        for attempt in range(1, max_attempts + 1):
            try:
                resp = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=float(temperature),
                )
                content = resp.choices[0].message.content
                return (content or "").strip() or "TITLE:\nBODY:"
            except Exception as e:
                print(f"[OpenAIClient] API Request Error (attempt {attempt}): {e}")
                if attempt < max_attempts:
                    time.sleep(backoff ** attempt)
                    continue
                break

        return (
            "TITLE: ì˜¤ë¥˜ ë°œìƒ\n"
            "BODY: OpenAI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )

    # -------------------------------------------------
    # compatibility wrapper (for StrategyNarrator)
    # -------------------------------------------------
    def generate(self, messages=None, system=None, user=None, temperature=0.7):
        # StrategyNarrator may call generate(messages=...)
        if messages is not None:
            return self.chat(messages=messages, temperature=temperature)

        # Or generate(system, user) style
        if system is not None and user is not None:
            return self.chat(
                messages=[
                    {"role": "system", "content": system},
                    {"role": "user", "content": user},
                ],
                temperature=temperature,
            )

        return self._dummy_response()

if __name__ == "__main__":
    # ë‹¨ë… í…ŒìŠ¤íŠ¸
    client = OpenAIChatCompletionClient()
    res = client.chat([
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ])
    print(res)
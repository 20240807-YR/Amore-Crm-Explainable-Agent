# agent10/strategy_narrator.py
import re
from typing import Any, Dict, List, Optional, Tuple


class StrategyNarrator:
    """
    - plan(message_outline) ì—†ìœ¼ë©´ generate ì‹¤í–‰ ê¸ˆì§€
    - BODYëŠ” 1:1:1:1 ìŠ¬ë¡¯(4ì¤„) ê°•ì œ: ë¼ì´í”„ìŠ¤íƒ€ì¼ â†’ ì œí’ˆ â†’ ë¼ì´í”„ìŠ¤íƒ€ì¼(ë£¨í‹´) â†’ ì¶”ê°€ ë©”ì‹œì§€(êµ¬ë§¤ í…€/ì±„ë„/í˜œíƒ)
    - BODY 300~350ì, URL ì •í™•íˆ 1íšŒ(ë§ˆì§€ë§‰), ë§ˆí¬ë‹¤ìš´ ë§í¬ ê¸ˆì§€
    - ë©”íƒ€/ê¸°íš/ì „ëµ í‘œí˜„ ê¸ˆì§€
    """

    def __init__(
        self,
        llm_client,
        pad_pool: Optional[List[str]] = None,
        tone_profile_map: Optional[Dict[str, Any]] = None,
        **kwargs,
    ):
        self.llm = llm_client
        self.tone_profile_map = tone_profile_map or {}
        self.pad_pool = pad_pool or [
            "ì˜¤ëŠ˜ ì»¨ë””ì…˜ì— ë§ì¶° ê°€ë³ê²Œ ë”í•˜ê¸° ì¢‹ì•„ìš”.",
            "ë¶€ë‹´ ì—†ì´ ë§¤ì¼ ì´ì–´ê°€ê¸° ì¢‹ì•„ìš”.",
            "ëˆì ì„ì´ ëœí•´ ë‹¤ìŒ ë‹¨ê³„ê¹Œì§€ ê¹”ë”í•´ìš”.",
            "ë°”ì ìˆ˜ë¡ ì§§ê²Œ ì •ë¦¬ë˜ëŠ” ë£¨í‹´ì´ ë” í¸í•´ìš”.",
            "ê°€ë³ê²Œ ë§ˆë¬´ë¦¬ë¼ ì•„ì¹¨ì—ë„ ë¶€ë‹´ì´ ëœí•´ìš”.",
        ]

        # slot4 ì „ìš© íŒ¨ë”© í’€ (ë¬¸ë‹¨ ë‹¨ìœ„ ìœ ì§€, ì§§ì€ ë¬¸ì¥ ë‚˜ì—´ ê¸ˆì§€)
        self.slot4_pad_pool = [
            "ë¶€ë‹´ ì—†ì´ ì´ì–´ê°€ê¸° ì¢‹ì•„ìš”.",
            "ê´€ë¦¬ í…€ì´ ì¡°ê¸ˆ ë¹„ì–´ë„ ë‹¤ì‹œ ì‹œì‘ì´ ê°€ë²¼ì›Œìš”.",
            "ì¼ìƒ íë¦„ì„ ëŠì§€ ì•Šê³  ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì ¸ìš”.",
        ]

        # meta/ê¸°íš/CTA ê¸ˆì§€(ê°•ì œ)
        self.meta_ban_phrases = [
            "ë¸Œëœë“œ í†¤ì„ ìœ ì§€í•˜ë©°",
            "ë¸Œëœë“œ í†¤ì„ ì‚´ë ¤",
            "ë¸Œëœë“œ í†¤ì„ ì‚´ë¦¬",
            "ì„¤ê³„ëœ ì œí’ˆ",
            "ê¸°íšëœ",
            "ì „ëµì ìœ¼ë¡œ",
            "í†¤ì„ ë°˜ì˜í•˜ì—¬",
            "ë¸Œëœë“œ ì•„ì´ë´í‹°í‹°",
            "í´ë¦­",
            "êµ¬ë§¤í•˜ê¸°",
            "ë” ì•Œì•„ë³´ë ¤ë©´",
            "ë” ì•Œì•„ë³´ê¸°",
            "ìì„¸íˆ ë³´ê¸°",
            # ë¬¸ì œë¡œ ì§€ì ëœ ì–´ìƒ‰í•œ ì¢…ê²°ë¬¸(ì§ì ‘ ì°¨ë‹¨)
            "ì§€ì† ê°€ëŠ¥ì„± ì¸¡ë©´ì—ì„œë„ ë¶€ë‹´ ì—†ì´ ì´ì–´ê°ˆ ìˆ˜",
            "ì´ ê³¼ì •ì—ì„œ ë£¨í‹´ ë‚´ ìœ„ì¹˜, ì§€ì† ê°€ëŠ¥ì„± ì¸¡ë©´ì—ì„œë„",
            "ìˆë‹¤",
            # slot4 ê²°ë¡ ë¶€ ì§ˆë¬¸í˜• ì¢…ê²° ì°¨ë‹¨ìš©
            "ì–´ë µì§€ ì•Šì£ ?",
            "í˜ë“¤ì§„ ì•Šë‚˜ìš”?",
            "ê´œì°®ì§€ ì•Šë‚˜ìš”?",
        ]
        # slot4(ê²°ë¡ ë¶€) ì§ˆë¬¸ì€ "ê²°ì • ìœ ë„í˜•"ë§Œ ì¡°ê±´ë¶€ í—ˆìš©
        # - í—ˆìš©: í–‰ë™ ìœ ë„/ì œì•ˆí˜• ì§ˆë¬¸
        # - ê¸ˆì§€: ë¬¸ì œ ì œê¸°í˜•(í˜ë“¤ì§„ ì•Šë‚˜ìš”? / ì–´ë µì§€ ì•Šë‚˜ìš”? ë“±)
        self.slot4_allow_question_patterns = [
            r"í•´ë³´ê³ \s*ì‹¶ë‹¤ë©´\?*$",
            r"í•´ë³´ëŠ”\s*ê±´\s*ì–´ë–¨ê¹Œìš”\?*$",
            r"í•´ë³´ê³ \s*ì‹¶ì§€\s*ì•Šë‚˜ìš”\?*$",
            r"ì‹œì‘í•´ë³´ì…”ë„\s*ì¢‹ì•„ìš”\.?$",
            r"í™•ì¸í•´ë³´ì„¸ìš”\.?$",
        ]
        self.slot4_ban_question_patterns = [
            r"í˜ë“¤\s*ì§„\s*ì•Šë‚˜ìš”\?*$",
            r"ì–´ë µ\s*ì§€\s*ì•Šë‚˜ìš”\?*$",
            r"ê´œì°®\s*ì§€\s*ì•Šë‚˜ìš”\?*$",
        ]
        self.meta_ban_regex = [
            r"ë¸Œëœë“œ\s*í†¤(ì„|ì´)?\s*(ìœ ì§€|ì‚´ë¦¬|ì‚´ë ¤|ë°˜ì˜)",
            r"(í´ë¦­|êµ¬ë§¤\s*í•˜ê¸°|êµ¬ë§¤í•˜ê¸°|ë”\s*ì•Œì•„\s*ë³´(ë ¤ë©´|ê¸°)|ìì„¸íˆ\s*ë³´(ê¸°|ë ¤ë©´))",
            r"(ì „ëµì |ê¸°íšëœ|ì„¤ê³„ëœ)\s*",
            r"ì§€ì†\s*ê°€ëŠ¥ì„±\s*ì¸¡ë©´",
            r"(ì´ë‹¤|ìˆë‹¤)$",
        ]
    def _strip_emojis(self, text: str) -> str:
        # Broad emoji unicode blocks
        return re.sub(r"[\U0001F300-\U0001FAFF]", "", self._s(text)).strip()

    def _replace_softeners(self, text: str) -> str:
        """
        ê´‘ê³  ì¹´í”¼ í†¤ì—ì„œ íŒë‹¨ì„ íë¦¬ëŠ” ì™„ê³¡ í‘œí˜„ì„ ìµœì†Œ ì¹˜í™˜í•œë‹¤.
        (ì˜ë¯¸ ì¬ì‘ì„±/í™•ì¥ ê¸ˆì§€, ë‹¨ìˆœ ì¹˜í™˜ë§Œ)
        """
        t = self._s(text)
        if not t:
            return t
        replacements = {
            "í¸ì´ì—ìš”": "ë£¨í‹´ì´ì—ìš”",
            "ê²ƒ ê°™ì•„ìš”": "ëŠê»´ì ¸ìš”",
            "ê°™ì•„ìš”": "ëŠê»´ì ¸ìš”",
        }
        for a, b in replacements.items():
            t = t.replace(a, b)
        return t

    def _enforce_slot_punct(self, slot_text: str, slot_id: int) -> str:
        """
        slotë³„ ë¬¸ì¥ë¶€í˜¸/ì´ëª¨ì§€ ê·œì¹™ì„ ì‚¬í›„ í†µì œí•œë‹¤.
        - slot1: '?' ìµœëŒ€ 1íšŒ í—ˆìš©, '!' ì œê±°
        - slot2/3: '?' ì œê±°, '!' 0~2íšŒ í—ˆìš©(ê³¼ë‹¤ ì‹œ 2íšŒë¡œ ì¶•ì†Œ), ì´ëª¨ì§€ ì œê±°
        - slot4: ê¸°ë³¸ì€ '?' ê¸ˆì§€. ë‹¨, "ê²°ì • ìœ ë„í˜•(ì œì•ˆí˜•)" ì§ˆë¬¸ë§Œ ì¡°ê±´ë¶€ í—ˆìš©
                (ë¬¸ì œ ì œê¸°í˜• ì§ˆë¬¸ì€ ê¸ˆì§€)
        """
        t = self._hard_clean(slot_text)
        t = self._replace_softeners(t)

        if slot_id in (1, 2, 3):
            t = self._strip_emojis(t)

        if slot_id == 1:
            t = t.replace("!", "")
            # keep at most one '?'
            if t.count("?") > 1:
                first = t.find("?")
                t = t[: first + 1] + t[first + 1 :].replace("?", "")
        elif slot_id in (2, 3):
            t = t.replace("?", "")
            # allow up to 2 '!'
            if t.count("!") > 2:
                # remove extras from the end
                extras = t.count("!") - 2
                while extras > 0:
                    idx = t.rfind("!")
                    if idx == -1:
                        break
                    t = t[:idx] + t[idx + 1 :]
                    extras -= 1
        else:  # slot4
            # slot4ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ê²°ë¡ ë¶€ ì§ˆë¬¸ì„ ê¸ˆì§€í•˜ë˜,
            # "ê²°ì • ìœ ë„í˜•(ì œì•ˆí˜•)" ì§ˆë¬¸ íŒ¨í„´ë§Œ ì¡°ê±´ë¶€ í—ˆìš©í•œë‹¤.
            tt = t

            # 1) ë¬¸ì œ ì œê¸°í˜• ì§ˆë¬¸ì€ ë¬´ì¡°ê±´ ì œê±°
            for rx in getattr(self, "slot4_ban_question_patterns", []):
                if re.search(rx, tt):
                    tt = tt.replace("?", "").strip()
                    break

            # 2) í—ˆìš© íŒ¨í„´ì´ë©´ '?'ë¥¼ ìœ ì§€ (ì—†ìœ¼ë©´ ì¶”ê°€í•˜ì§€ ì•ŠìŒ)
            if "?" in tt:
                allowed = False
                for rx in getattr(self, "slot4_allow_question_patterns", []):
                    if re.search(rx, tt):
                        allowed = True
                        break
                if not allowed:
                    tt = tt.replace("?", "").strip()

            # 3) ëŠë‚Œí‘œëŠ” ìµœëŒ€ 1íšŒ
            if tt.count("!") > 1:
                extras = tt.count("!") - 1
                while extras > 0:
                    idx = tt.rfind("!")
                    if idx == -1:
                        break
                    tt = tt[:idx] + tt[idx + 1 :]
                    extras -= 1

            # emoji only in slot4, but prevent obvious spam like "!!!" or repeated sparkles
            tt = re.sub(r"(!){2,}", "!", tt)
            t = tt

        return t.strip()
    def _build_slot23_expansion_sentence(self, row: Dict[str, Any], plan: Dict[str, Any], slot_id: int) -> str:
        """Deterministic, non-LLM expansion sentence for slot2/slot3.

        - ëª©ì : BODYê°€ 300ì ë¯¸ë§Œì¼ ë•Œ slot4 íŒ¨ë”© ë‚¨ë°œ ì—†ì´ ê¸¸ì´ë¥¼ í™•ë³´.
        - ì›ì¹™: ì˜ë¯¸ ì™œê³¡/ì¶”ì • ê¸ˆì§€. row/plan/persona_fieldsì— ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ê°’ë§Œ ì‚¬ìš©.
        - slot2/slot3ì—ë§Œ ì‚¬ìš©(ì´ëª¨ì§€ ê¸ˆì§€, '?' ê¸ˆì§€).
        """
        pf = plan.get("persona_fields") or {}

        texture = self._s(pf.get("texture_preference") or row.get("texture_preference"))
        finish = self._s(pf.get("finish_preference") or row.get("finish_preference"))
        scent = self._s(pf.get("scent_preference") or row.get("scent_preference"))
        routine_steps = self._s(pf.get("routine_step_count") or row.get("routine_step_count"))
        time_of_use = self._s(pf.get("time_of_use") or row.get("time_of_use"))
        seasonality = self._s(pf.get("seasonality") or row.get("seasonality"))
        shopping_channel = self._s(pf.get("shopping_channel") or row.get("shopping_channel"))
        repurchase = self._s(pf.get("repurchase_tendency") or row.get("repurchase_tendency"))
        allergy = self._s(pf.get("allergy_sensitivity") or row.get("allergy_sensitivity"))
        avoid = self._s(pf.get("ingredient_avoid_list") or row.get("ingredient_avoid_list"))

        # Build a single sentence using only available facts.
        parts: List[str] = []

        if texture:
            parts.append(f"{texture} ê²°ì„ ì¢‹ì•„í•œë‹¤ë©´")
        if finish:
            parts.append(f"ë§ˆë¬´ë¦¬ëŠ” {finish} ìª½ì´ í¸í•˜ê³ ")
        if scent:
            parts.append(f"í–¥ì€ {scent} ìª½ì´ ë” ì•ˆì •ì ì´ì—ìš”")

        # Allergy/avoid: only mention if present (no new ingredient claims)
        if allergy or avoid:
            tmp = []
            if allergy:
                tmp.append(allergy)
            if avoid:
                tmp.append(avoid)
            parts.append(f"ë¯¼ê° í¬ì¸íŠ¸ëŠ” {', '.join(tmp)}ì²˜ëŸ¼ ê°€ë³ê²Œ ì±™ê¸°ë©´ ì¢‹ê³ ")

        if routine_steps or time_of_use:
            rs = routine_steps if routine_steps else "ì§§ì€"
            to = time_of_use if time_of_use else "í•˜ë£¨"
            parts.append(f"{to} {rs}ë‹¨ê³„ ë£¨í‹´ì—ë„ ë¶€ë‹´ ì—†ì´ ë¶™ì–´ìš”")

        if seasonality:
            parts.append(f"{seasonality}ì²˜ëŸ¼ ì»¨ë””ì…˜ì´ í”ë“¤ë¦¬ëŠ” ë•Œì—ë„")

        if shopping_channel or repurchase:
            ch = shopping_channel if shopping_channel else "êµ¬ë§¤"
            rp = repurchase if repurchase else "ì¬êµ¬ë§¤"
            parts.append(f"{ch}ì—ì„œ {rp} íë¦„ìœ¼ë¡œ ì´ì–´ê°€ê¸°ì—ë„ ì¢‹ì•„ìš”")

        # Fallback if everything is empty
        if not parts:
            return "ê°€ë²¼ìš´ ì‚¬ìš©ê°ìœ¼ë¡œ ë£¨í‹´ì— ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ë„ë¡ ì¡ì•„ì¤ë‹ˆë‹¤!"

        sent = " ".join(parts).strip()
        # Ensure it ends as a confident ad copy sentence.
        if not sent.endswith(".") and not sent.endswith("!"):
            sent = sent + "!"

        # slot2/3 rule enforcement (no '?' / no emoji)
        sent = sent.replace("?", "")
        sent = self._strip_emojis(sent)
        return self._hard_clean(sent)

    # -------------------------
    # utils
    # -------------------------
    def _s(self, v: Any) -> str:
        return "" if v is None else str(v).strip()

    def _as_text(self, v: Any) -> str:
        """Normalize possible list/tuple fields into a clean, single string."""
        if v is None:
            return ""
        if isinstance(v, (list, tuple)):
            parts: List[str] = []
            for x in v:
                s = self._s(x)
                if not s:
                    continue
                # remove leading bullet markers like "- ", "â€¢ "
                s = re.sub(r"^\s*[-â€¢]\s*", "", s)
                if s:
                    parts.append(s)
            return " ".join(parts).strip()
        return self._s(v)

    def _lifestyle_phrase(self, lifestyle: str) -> str:
        """
        slot1(í™˜ê²½/ìƒí™©)ìš© ë¼ì´í”„ìŠ¤íƒ€ì¼ ë¬¸êµ¬ ìƒì„±.
        - í–‰ë™/ë£¨í‹´/ì‹œê°„(ì˜ˆ: "ì¶œê·¼ ì „ 5ë¶„ ë£¨í‹´")ì€ slot1ì—ì„œ ì œê±°í•œë‹¤.
        - ìˆ«ìë§Œ ë‚¨ì•„ "5ì—" ê°™ì€ íŒŒí¸ì´ ìƒê¸°ì§€ ì•Šë„ë¡ ë°©ì§€í•œë‹¤.
        - "ë§ˆìŠ¤í¬ ì¦ìŒ"ì²˜ëŸ¼ ëª…ì‚¬ í‚¤ì›Œë“œëŠ” ìì—°ì–´ë¡œ ìµœì†Œ ì •ê·œí™”í•œë‹¤.
        """
        raw = self._s(lifestyle)
        if not raw:
            return ""

        # 1) ì½¤ë§ˆ ê¸°ë°˜ í‚¤ì›Œë“œ ë¶„ë¦¬
        tokens = [t.strip() for t in raw.split(",") if t and t.strip()]
        if not tokens:
            return ""

        # 2) slot1ì—ì„œ ë°°ì œí•´ì•¼ í•˜ëŠ”(í–‰ë™/ë£¨í‹´/ì‹œê°„) ë§ˆì»¤
        routine_markers = ["ë£¨í‹´", "ì¶œê·¼", "ë¶„", "ì•„ì¹¨", "ì €ë…", "ë‹¨ê³„", "ì „", "í›„", "ì„¸ì•ˆ", "í† ë„ˆ"]

        env_tokens: List[str] = []
        for t in tokens:
            # ë£¨í‹´/ì‹œê°„ í† í°ì€ slot1ì—ì„œ ì œì™¸
            if any(m in t for m in routine_markers):
                continue

            # ìˆ«ì/ê¸°í˜¸ë§Œ ë‚¨ì€ í† í° ì œê±° (ì˜ˆ: "5")
            if re.fullmatch(r"[0-9]+", t):
                continue

            # ìµœì†Œ ìì—°ì–´ ì •ê·œí™”
            tt = t
            # 'ì¦ìŒ' â†’ 'ì¦ì€' í˜•íƒœë¡œ ì •ê·œí™”
            tt = tt.replace("ì¦ìŒ", "ì¦ì€")
            # 'ë§ˆìŠ¤í¬ ì¦ì€' â†’ 'ë§ˆìŠ¤í¬ ì°©ìš©ì´ ì¦ì€'
            if "ë§ˆìŠ¤í¬" in tt and "ì°©ìš©" not in tt:
                # 'ë§ˆìŠ¤í¬ ì¦ì€' / 'ë§ˆìŠ¤í¬ ì¦ì€ í™˜ê²½' ë“±
                tt = tt.replace("ë§ˆìŠ¤í¬", "ë§ˆìŠ¤í¬ ì°©ìš©")
            if "ë§ˆìŠ¤í¬ ì°©ìš©" in tt and "ì¦" in tt and "ì°©ìš©ì´" not in tt:
                tt = tt.replace("ë§ˆìŠ¤í¬ ì°©ìš©", "ë§ˆìŠ¤í¬ ì°©ìš©ì´")

            # 'ì‚¬ë¬´ì‹¤ ì—ì–´ì»¨'ì€ 'ì—ì–´ì»¨ ë°”ëŒ'ìœ¼ë¡œ ìì—°í™”
            if "ì—ì–´ì»¨" in tt and "ë°”ëŒ" not in tt:
                tt = tt.replace("ì—ì–´ì»¨", "ì—ì–´ì»¨ ë°”ëŒ")

            tt = tt.strip()
            if not tt:
                continue
            env_tokens.append(tt)

        # 3) í™˜ê²½ í† í°ì´ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ë¬´ë¦¬í•˜ê²Œ ë§Œë“¤ì§€ ì•Šê³  ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
        # (slot1 ê¸°ë³¸ ë¬¸ì¥ í…œí”Œë¦¿ì—ì„œ ì•ˆì „í•œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì²˜ë¦¬)
        if not env_tokens:
            return ""

        # 4) slot1 ë¬¸ì¥ ì•ë¶€ë¶„ìš© êµ¬ë¬¸ ìƒì„± (ì¡°ì‚¬ ì¶©ëŒ/ì¤‘ë³µ ìµœì†Œí™”)
        if len(env_tokens) == 1:
            return env_tokens[0]
        if len(env_tokens) == 2:
            return f"{env_tokens[0]}ê¹Œì§€ ê²¹ì¹˜ëŠ” ë‚ ì—”"

        # 3ê°œ ì´ìƒì´ë©´ ì• 3ê°œë§Œ ì‚¬ìš©
        a, b, c = env_tokens[0], env_tokens[1], env_tokens[2]
        return f"{a}ê¹Œì§€ ê²¹ì¹˜ê³ , {b}ë„ ëŠê»´ì§€ëŠ” ë°ë‹¤ {c}ê¹Œì§€ ì‹ ê²½ ì“°ì´ëŠ” ë‚ ì—”"

    def _get_url(self, row: Dict[str, Any]) -> str:
        for k in ["url", "URL", "product_url", "productURL", "ìƒí’ˆURL", "ìƒí’ˆ_url", "link", "ë§í¬"]:
            v = self._s(row.get(k))
            if v and v.lower() != "nan":
                return v
        return ""

    def _strip_markdown_link(self, text: str) -> str:
        return re.sub(r"\[([^\]]+)\]\(https?://[^\)]+\)", r"\1", text)

    def _contains_banned(self, text: str) -> bool:
        if not text:
            return False
        for p in self.meta_ban_phrases:
            if p and p in text:
                return True
        for rx in self.meta_ban_regex:
            if re.search(rx, text):
                return True
        return False

    def _hard_clean(self, text: str) -> str:
        t = self._s(text)
        t = self._strip_markdown_link(t)
        t = re.sub(r"https?://[^\s]+", "", t, flags=re.IGNORECASE)
        t = re.sub(r"\s+", " ", t).strip()
        return t

    def _ensure_title_len(self, title: str) -> str:
        title = self._s(title)
        if len(title) <= 40:
            return title
        return title[:40].rstrip()

    def _split_4lines(self, body: str) -> List[str]:
        lines = [ln.strip() for ln in self._s(body).split("\n") if ln.strip()]
        if len(lines) >= 4:
            return lines[:4]
        parts = re.split(r"[.!?â€¦~]+", self._s(body))
        parts = [p.strip() for p in parts if p and p.strip()]
        if len(parts) >= 4:
            return parts[:4]
        while len(lines) < 4:
            lines.append("")
        if not lines[0]:
            lines[0] = self._s(body)
        return lines[:4]

    def _join_4lines(self, lines: List[str]) -> str:
        lines = [self._s(x) for x in lines[:4]]
        # 4ë¬¸ë‹¨(4ì¤„) êµ¬ì¡°ë¥¼ ê¹¨ì§€ì§€ ì•Šê²Œ ìœ ì§€ (ë¹ˆ ì¤„ë„ ë³´ì¡´)
        while len(lines) < 4:
            lines.append("")
        return "\n".join(lines[:4])

    def _build_slot4_paragraph(self, brand_name: str, avoid_phrases: Optional[List[str]] = None) -> str:
        """
        slot4ëŠ” í•­ìƒ í•˜ë‚˜ì˜ ë¬¸ë‹¨ìœ¼ë¡œ ìƒì„±í•œë‹¤.
        - pad_pool/slot4_pad_pool ë¬¸êµ¬ëŠ” slot4ì—ì„œë§Œ 1íšŒ ì‚¬ìš©(ì½˜í…ì¸  ì£¼ë„ ê¸ˆì§€)
        - ê°™ì€ ì™„ê³¡ ë¬¸êµ¬ë¥¼ ì—¬ëŸ¬ ë²ˆ ëˆ„ì í•˜ì§€ ì•ŠëŠ”ë‹¤.
        """
        avoid_phrases = avoid_phrases or []

        # ê¸°ë³¸ 2ë¬¸ì¥ + (ì„ íƒ) pad 1ë¬¸ì¥ + (ì„ íƒ) ë¸Œëœë“œ í´ë¡œì§• 1ë¬¸ì¥
        base_1 = "ê´€ë¦¬ í…€ì´ ì¡°ê¸ˆ ë¹„ì–´ë„ ê´œì°®ì•„ìš”."

        # slot4_pad_poolì—ì„œ 1ê°œë§Œ ì„ íƒí•˜ë˜, ë™ì¼ ë¬¸êµ¬ ë°˜ë³µì„ í”¼í•œë‹¤.
        pad = ""
        if self.slot4_pad_pool:
            # ì²« ë¬¸ì¥(ê´€ë¦¬ í…€)ê³¼ ì˜ë¯¸ê°€ ê²¹ì¹˜ì§€ ì•ŠëŠ” ë¬¸ì¥ ìš°ì„ 
            candidates = [s for s in self.slot4_pad_pool if s and s not in base_1]
            pad = candidates[0] if candidates else self.slot4_pad_pool[0]

        base_2 = "ì˜¤ëŠ˜ ì»¨ë””ì…˜ì— ë§ì¶° ê°€ë³ê²Œ ì–¹ê¸° ì¢‹ì•„ìš”."

        closing = ""
        if self._s(brand_name):
            closing = f"{brand_name}ì™€ í•¨ê»˜ë¼ë©´ ì¼ìƒ íë¦„ì„ ëŠì§€ ì•Šê³  ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì ¸ìš”."

        # padëŠ” 1íšŒë§Œ í¬í•¨
        parts = [base_1]
        if pad:
            parts.append(pad)
        parts.append(base_2)
        if closing:
            parts.append(closing)

        paragraph = " ".join([self._s(p) for p in parts if self._s(p)])

        for p in avoid_phrases:
            paragraph = paragraph.replace(p, "")

        return self._hard_clean(paragraph)

    def _fit_len_300_350(self, lines: List[str]) -> Tuple[List[str], str]:
        lines = [self._hard_clean(x) for x in lines]
        body = self._join_4lines(lines)

        # ê¸¸ì´ ë³´ì •ì€ slot4ì—ì„œë§Œ ìˆ˜í–‰í•œë‹¤.
        # - pad_pool/slot4_pad_pool ë¬¸êµ¬ëŠ” slot4ì—ì„œ 1íšŒë§Œ ì‚¬ìš©
        # - slot1~3ì—ëŠ” ì–´ë–¤ ê²½ìš°ì—ë„ padë¥¼ ë¶™ì´ì§€ ì•ŠëŠ”ë‹¤.
        if len(body) < 300:
            # slot4ê°€ ë¹„ì–´ ìˆìœ¼ë©´ ê¸°ë³¸ ë¬¸ë‹¨ìœ¼ë¡œ ì±„ì›€
            if not self._s(lines[3]):
                lines[3] = self._build_slot4_paragraph("")
            else:
                lines[3] = self._hard_clean(lines[3])

            # (1) pad í’€ ë¬¸êµ¬ëŠ” 1íšŒë§Œ ì¶”ê°€ (ì¤‘ë³µì´ë©´ ìŠ¤í‚µ)
            pad_added = False
            pad_sources = []
            if self.slot4_pad_pool:
                pad_sources.extend(self.slot4_pad_pool)
            elif self.pad_pool:
                pad_sources.extend(self.pad_pool)

            for cand in pad_sources:
                cand = self._s(cand)
                if not cand:
                    continue
                if cand in lines[3]:
                    continue
                lines[3] = self._hard_clean(lines[3] + " " + cand)
                pad_added = True
                break

            body = self._join_4lines(lines)

            # (2) ê·¸ë˜ë„ 300 ë¯¸ë§Œì´ë©´ slot4ì— ë¬¸ì¥ì„ ë” ìŒ“ì§€ ì•Šê³ ,
            #     slot2/slot3ì— 'ì‚¬ì‹¤ ê¸°ë°˜' í™•ì¥ ë¬¸ì¥ 1ê°œì”©ë§Œ ì¶”ê°€í•œë‹¤.
            if len(body) < 300:
                exp2 = self._build_slot23_expansion_sentence({}, {}, 2)
                exp3 = self._build_slot23_expansion_sentence({}, {}, 3)

                # row/plan ì •ë³´ê°€ ìˆëŠ” ê²½ìš° generate()ì—ì„œ ë‹¤ì‹œ ì£¼ì…í•  ìˆ˜ ìˆë„ë¡,
                # ì—¬ê¸°ì„œëŠ” linesì— ì´ë¯¸ ë“¤ì–´ìˆëŠ” ë¬¸ì¥ì„ ìš°ì„  í™•ì¥í•œë‹¤.
                # (fallback ë¬¸ì¥ë§Œ ì“°ì§€ ì•Šë„ë¡, generate()ì—ì„œ row/planì„ ì „ë‹¬í•´ ì¬í˜¸ì¶œí•˜ëŠ” êµ¬ì¡°ê°€ ê°€ì¥ ì¢‹ì§€ë§Œ
                #  ì´ í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ ì•„ë˜ëŠ” ìµœì†Œ ì•ˆì „ í™•ì¥ë§Œ ìˆ˜í–‰)
                if exp2 and exp2 not in lines[1]:
                    lines[1] = self._hard_clean((lines[1] + " " + exp2).strip())
                    lines[1] = self._enforce_slot_punct(lines[1], 2)
                body = self._join_4lines(lines)

            if len(body) < 300:
                exp3 = self._build_slot23_expansion_sentence({}, {}, 3)
                if exp3 and exp3 not in lines[2]:
                    lines[2] = self._hard_clean((lines[2] + " " + exp3).strip())
                    lines[2] = self._enforce_slot_punct(lines[2], 3)
                body = self._join_4lines(lines)

        # ìµœì¢… slot ê·œì¹™ ì¬ê°•ì œ(í™•ì¥/íŒ¨ë”© ì´í›„)
        lines[0] = self._enforce_slot_punct(lines[0], 1)
        lines[1] = self._enforce_slot_punct(lines[1], 2)
        lines[2] = self._enforce_slot_punct(lines[2], 3)
        lines[3] = self._enforce_slot_punct(lines[3], 4)
        body = self._join_4lines(lines)

        # ìƒí•œì€ ìë¥´ë˜, ì¤„ êµ¬ì¡°ëŠ” ìœ ì§€
        if len(body) > 350:
            body = body[:350].rstrip()

        return lines, body
    def _dedupe_body_ngrams(self, body: str, n: int = 6) -> str:
        """
        BODY ì „ì²´ ê¸°ì¤€ n-gram ì¤‘ë³µì„ ì œê±°í•œë‹¤.
        - ì›ì¹™: "ì‚­ì œë§Œ" ìˆ˜í–‰ (ëŒ€ì²´ ë¬¸ì¥ ìƒì„± ê¸ˆì§€)
        - ì¤„(ìŠ¬ë¡¯) êµ¬ì¡°ëŠ” ìœ ì§€
        - ê°™ì€ êµ¬ë¬¸ì´ ë°˜ë³µë˜ë©´ "ë’¤ìª½" ë¬¸ì¥ë¶€í„° ì œê±°
        """
        text = self._s(body)
        if not text:
            return ""

        # ì¤„(ìŠ¬ë¡¯) ë‹¨ìœ„ ìœ ì§€
        lines = [ln.strip() for ln in text.split("\n")]

        def split_sentences(s: str) -> List[str]:
            # ê³¼ë„í•œ ë¶„í•´ë¥¼ í”¼í•˜ê¸° ìœ„í•´ ë§ˆì¹¨í‘œ/ë¬¼ìŒí‘œ/ëŠë‚Œí‘œ/ë¬¼ê²°/â€¦ ê¸°ì¤€ë§Œ ë¶„ë¦¬
            parts = re.split(r"(?<=[\.!?â€¦~])\s+", self._s(s))
            return [p.strip() for p in parts if p and p.strip()]

        seen = set()
        out_lines: List[str] = []

        for line in lines:
            sents = split_sentences(line)
            kept: List[str] = []
            for sent in sents:
                toks = sent.split()
                # ë„ˆë¬´ ì§§ìœ¼ë©´ n-gram ê¸°ë°˜ ì¤‘ë³µ íŒë‹¨ì„ í•˜ì§€ ì•ŠìŒ
                if len(toks) < n:
                    kept.append(sent)
                    continue

                dup = False
                for i in range(len(toks) - n + 1):
                    ng = tuple(toks[i : i + n])
                    if ng in seen:
                        dup = True
                        break

                if dup:
                    # "ì‚­ì œë§Œ": ì¤‘ë³µ ë¬¸ì¥ì€ ë²„ë¦°ë‹¤.
                    continue

                # ìµœì´ˆ ë“±ì¥ n-gram ê¸°ë¡
                for i in range(len(toks) - n + 1):
                    seen.add(tuple(toks[i : i + n]))
                kept.append(sent)

            out_lines.append(" ".join(kept).strip())

        # ëª¨ë“  ë¬¸ì¥ì´ ì‚­ì œë˜ëŠ” ê·¹ë‹¨ ì¼€ì´ìŠ¤ ë°©ì–´
        joined = "\n".join([self._s(x) for x in out_lines])
        return joined if self._s(joined) else text

    def _ensure_len_300_350(self, body: str) -> str:
        """
        Compatibility wrapper.
        generate() expects _ensure_len_300_350, but legacy logic uses _fit_len_300_350.
        This method adapts the existing implementation without changing behavior.
        """
        lines = self._split_4lines(body)
        _, final_body = self._fit_len_300_350(lines)
        # ë¹ˆ ë°”ë”” ë°©ì–´: ì ˆëŒ€ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜ ê¸ˆì§€
        if not self._s(final_body):
            _, final_body = self._fit_len_300_350(["", "", "", ""])
        return final_body

    # -------------------------
    # prompt builders
    # -------------------------
    def _build_system_prompt(self, brand_name: str) -> str:
        """
        ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: STRICT SLOT-ONLY, TITLE/BODY ì˜ˆì‹œÂ·ë¼ë²¨Â·êµ¬ì¡° ê¸ˆì§€
        """
        return """
ë„ˆëŠ” ê³ ê° ìƒë‹´ìë‚˜ CS ì§ì›ì´ ì•„ë‹ˆë‹¤.
ë„ˆëŠ” ë‚´ë¶€ ë§ˆì¼€íŒ… ë‹´ë‹¹ìë‹¤.

ëª©í‘œ:
- ì •ë³´ ë¬¸ì¥ì´ ì•„ë‹ˆë¼ 'ì •ì œëœ ê´‘ê³  ì¹´í”¼'ë¥¼ ì“´ë‹¤.
- "ê´‘ê³ ì²˜ëŸ¼ ë³´ì´ëŠ” ê²ƒ"ì€ ë¬¸ì œê°€ ì•„ë‹ˆë¼ ëª©í‘œë‹¤.
- BODYëŠ” ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë¼ ê´‘ê³  ë¬¸ë‹¨(ì¹´í”¼) íë¦„ì´ë‹¤.

ë¬¸ë‹¨(ìŠ¬ë¡¯) êµ¬ì„±:
- BODYëŠ” 4ê°œ ìŠ¬ë¡¯(4ì¤„) êµ¬ì¡°ë¥¼ ê°€ì§„ë‹¤.
- ê° ìŠ¬ë¡¯ì€ 2~3ë¬¸ì¥ê¹Œì§€ í—ˆìš©ëœë‹¤(ë¬¸ì¥ ë‚˜ì—´ì‹ 1ë¬¸ì¥ë§Œ ë°˜ë³µ ê¸ˆì§€).
- slot2 + slot3ì€ í•˜ë‚˜ì˜ ê´‘ê³  ë¬¸ë‹¨ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ë˜ì–´ë„ ëœë‹¤.

ë¬¸ì¥ë¶€í˜¸/ì´ëª¨ì§€ ê·œì¹™(ê°•ì œ):
- slot1: '?' ìµœëŒ€ 1íšŒ í—ˆìš©, '!' ê¸ˆì§€, ì´ëª¨ì§€ ê¸ˆì§€
- slot2/slot3: '?' ê¸ˆì§€, '!' 1~2íšŒ í—ˆìš©, ì´ëª¨ì§€ ê¸ˆì§€
- slot4: '?' ê¸°ë³¸ ê¸ˆì§€. ë‹¨, ê²°ë¡ ë¶€ëŠ” ë‹¨ì •ì  ë¬¸ì¥ ë˜ëŠ” 'ê²°ì • ìœ ë„í˜•(ì œì•ˆí˜•)' ì§ˆë¬¸ìœ¼ë¡œ ë§ˆë¬´ë¦¬ ê°€ëŠ¥(ë¬¸ì œ ì œê¸°í˜• ì§ˆë¬¸ ê¸ˆì§€). '!' 0~1íšŒ í—ˆìš©, ì´ëª¨ì§€ëŠ” âœ¨ğŸ’§ ì •ë„ë§Œ 1íšŒ í—ˆìš©

ì „ê°œ ê·œì¹™:
- slot1ì€ ìƒí™© ë„ì…/ê³µê°ìœ¼ë¡œ ê´€ì‹¬ì„ ëŒê³ , ì§ˆë¬¸ì€ ì—¬ê¸°ì„œë§Œ ì œí•œì ìœ¼ë¡œ ì“´ë‹¤.
- slot2ëŠ” "ê·¸ë˜ì„œ/ì´ëŸ´ ë•Œ/ì´ëŸ° ë¶„ê»˜" ê°™ì€ ì—°ê²°ì–´ë¡œ slot1ì„ ì´ì–´ì„œ ì œí’ˆ ì œì•ˆì„ í•œë‹¤(ì œí’ˆëª… ìì—°ìŠ¤ëŸ½ê²Œ 1íšŒ ì´ìƒ í¬í•¨).
- slot3ì€ ì‚¬ìš© ì¥ë©´/ë£¨í‹´ì„ 'ì„¤ëª…'í•˜ì§€ ë§ê³ , slot2ì˜ íë¦„ì„ ì´ì–´ ì²´ê°/ì‚¬ìš©ê°ì„ ë¶™ì—¬ì¤€ë‹¤.
- slot4ëŠ” ë‹¨ì •ì Â·í™•ì‹ í˜• ì¹´í”¼ë¡œ ë§ˆë¬´ë¦¬í•˜ê³ , ì§ˆë¬¸ì„ ë‚¨ê¸°ì§€ ì•ŠëŠ”ë‹¤.

ê¸ˆì§€:
- ì •ë³´ ë‚˜ì—´ì‹ ì„¤ëª…
- ê²°ë¡ ë¶€ ì§ˆë¬¸(ì˜ˆ: "í˜ë“¤ì§„ ì•Šë‚˜ìš”?", "ì–´ë µì§€ ì•Šì£ ?")
- ê³¼ë„í•œ ì¼ìƒ íšŒí™” ì™„ê³¡(ì˜ˆ: "~ì¸ ê²ƒ ê°™ì•„ìš”", "ì†ì´ ìì£¼ ê°€ëŠ” í¸ì´ì—ìš”")
- ì„¤ëª…ì²´/í•˜ë‹¤ì²´/~ì´ë‹¤/~í•©ë‹ˆë‹¤
"""

    def _build_user_prompt(
        self,
        row: Dict[str, Any],
        plan: Dict[str, Any],
        brand_rule: Dict[str, Any],
        repair_errors: Optional[List[str]] = None,
    ) -> str:
        brand_name = self._s(row.get("brand", ""))
        product_name = self._s(row.get("ìƒí’ˆëª…", "ì œí’ˆ"))
        
        must_include = plan.get("brand_must_include", [])
        must_str = ", ".join(must_include) if must_include else "ì—†ìŒ"

        # ë¸Œëœë“œ ê·œì¹™ ë³‘í•©
        rule_text = ""
        banned = self._s(brand_rule.get("banned", ""))
        avoid = self._s(brand_rule.get("avoid", ""))
        if banned:
            rule_text += f"- ì ˆëŒ€ ê¸ˆì§€ì–´: {banned}\n"
        if avoid:
            rule_text += f"- ì§€ì–‘í•  í‘œí˜„: {avoid}\n"

        prompt = f"""
[ê³ ê° ì •ë³´]
- ìƒí™©(Lifestyle): {self._as_text(plan.get('lifestyle_expanded') or row.get('lifestyle', ''))}
- í”¼ë¶€ ê³ ë¯¼: {self._s(row.get('skin_concern', ''))}
- ì¶”ì²œ ì œí’ˆ: {product_name}
- í•„ìˆ˜ í¬í•¨ í‚¤ì›Œë“œ: {must_str} (ë¬¸ì¥ ì†ì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ë‚´ì„¸ìš”)
{rule_text}
[ìš”ì²­ ì‚¬í•­]
ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {brand_name}ì˜ í†¤ì•¤ë§¤ë„ˆì— ë§ëŠ” ë§¤ë ¥ì ì¸ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.
ë°˜ë“œì‹œ ì‹œìŠ¤í…œ ì§€ì‹œì˜ slot1_text~slot4_text í˜•ì‹ë§Œ ë”°ë¥´ì„¸ìš”. TITLE/BODY ê°™ì€ ë¼ë²¨ì€ ì ˆëŒ€ ì“°ì§€ ë§ˆì„¸ìš”.
"""
        if repair_errors:
            prompt += f"\n[ìˆ˜ì • ìš”ì²­] ì´ì „ ìƒì„± ê²°ê³¼ì— ë‹¤ìŒ ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ ë°˜ì˜í•˜ì—¬ ìˆ˜ì •í•˜ì„¸ìš”: {', '.join(repair_errors)}"

        return prompt

    def _build_user_prompt_free(
        self,
        row: Dict[str, Any],
        plan: Dict[str, Any],
        brand_rule: Dict[str, Any],
    ) -> str:
        brand_name = self._s(row.get("brand", ""))
        product_name = self._s(row.get("ìƒí’ˆëª…", "ì œí’ˆ"))

        prompt = f"""
[ì‘ì„± ì§€ì‹œ]
ì•„ë˜ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ {brand_name}ì˜ ë§ˆì¼€íŒ… ë©”ì‹œì§€ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

- ì¶œë ¥ì€ ë°˜ë“œì‹œ 4ê°œ ë¬¸ë‹¨(ìŠ¬ë¡¯)ë¡œë§Œ êµ¬ì„±
- ë¬¸ë‹¨ê³¼ ë¬¸ë‹¨ ì‚¬ì´ëŠ” 'ë¹ˆ ì¤„(\\n\\n)'ë¡œ êµ¬ë¶„
- ê° ë¬¸ë‹¨ì€ 2~3ë¬¸ì¥ê¹Œì§€ í—ˆìš© (ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ì²˜ëŸ¼ 1ë¬¸ì¥ë§Œ ë‚˜ì—´ ê¸ˆì§€)
- ì§ˆë¬¸('?')ì€ 1ë¬¸ë‹¨(slot1)ì—ì„œë§Œ ìµœëŒ€ 1íšŒ í—ˆìš©, 4ë¬¸ë‹¨(slot4)ì€ ê¸°ë³¸ ê¸ˆì§€(ë‹¨, 'ê²°ì • ìœ ë„í˜•(ì œì•ˆí˜•)' ì§ˆë¬¸ë§Œ í—ˆìš©)
- 2~3ë¬¸ë‹¨(slot2/slot3)ì—ì„œëŠ” '!' 1~2íšŒ í—ˆìš©, ì´ëª¨ì§€ ê¸ˆì§€
- 4ë¬¸ë‹¨(slot4)ë§Œ ì´ëª¨ì§€ 1ê°œ í—ˆìš©(âœ¨ ë˜ëŠ” ğŸ’§), '!'ì€ 1íšŒê¹Œì§€ í—ˆìš©
- ì œí’ˆëª…ì€ 2~3ë¬¸ë‹¨ ì–´ë”˜ê°€ì— ìì—°ìŠ¤ëŸ½ê²Œ 1íšŒ ì´ìƒ í¬í•¨
- ì„¤ëª…/ë¶„ì„/ìê¸°ì†Œê°œ ê¸ˆì§€, ê´‘ê³  ì¹´í”¼ í†¤ ìœ ì§€

[ê³ ê° ì •ë³´]
- ë¼ì´í”„ìŠ¤íƒ€ì¼: {row.get('lifestyle', '')}
- í”¼ë¶€ ê³ ë¯¼: {row.get('skin_concern', '')}
- ì¶”ì²œ ì œí’ˆ: {product_name}
"""
        return prompt


    # -------------------------
    # New slot helper prompt builders
    # -------------------------
    def _build_user_prompt_slot_expand(self, free_text: str) -> str:
        """
        Asks LLM to output exactly 4 slots from the given text, no rewriting.
        """
        return (
            "ì•„ë˜ í…ìŠ¤íŠ¸ì˜ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ 4ê°œì˜ ìŠ¬ë¡¯ì„ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ë¶„ë¦¬í•´ ì£¼ì„¸ìš”:\n"
            "SLOT1:\n...\nSLOT2:\n...\nSLOT3:\n...\nSLOT4:\n...\n"
            "\n[ê·œì¹™]\n"
            "- ë°˜ë“œì‹œ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì˜ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”. ì–´ë–¤ ìƒˆë¡œìš´ í‘œí˜„, ì–´íˆ¬, ì¬êµ¬ì„±, ì¶”ê°€ ì •ë³´ë„ ê¸ˆì§€í•©ë‹ˆë‹¤.\n"
            "- ê° ìŠ¬ë¡¯ì€ 1~2ë¬¸ì¥ìœ¼ë¡œ, ì›ë¬¸ì—ì„œ í•„ìš”í•œ ë¶€ë¶„ë§Œ ë°œì·Œí•˜ì„¸ìš”.\n"
            "- ì–´ë– í•œ ê²½ìš°ì—ë„ TITLE/BODYë¼ëŠ” ë‹¨ì–´, ë¼ë²¨, ì„¤ëª…ì€ ë„£ì§€ ë§ˆì„¸ìš”.\n"
            "- SLOT1~4 ë ˆì´ë¸”ì€ ë°˜ë“œì‹œ ì •í™•íˆ ì§€í‚¤ì„¸ìš”.\n"
            "\n[ì…ë ¥ í…ìŠ¤íŠ¸]\n"
            f"{free_text}\n"
        )

    def _build_user_prompt_slot_summarize(self, slot_text: str, slot_id: int) -> str:
        """
        Summarizes slot text to strict char count, per slot.
        """
        char_rules = {
            1: "60~80ì (í™˜ê²½/ìƒí™©)",
            2: "80~100ì (í”¼ë¶€ ê³ ë¯¼+ì œí’ˆ)",
            3: "70~90ì (ë£¨í‹´/ì‹œê°„ëŒ€ í•„ìˆ˜)",
            4: "60~80ì (ì§€ì†/êµ¬ë§¤ í…€)"
        }
        rule = char_rules.get(slot_id, "70~90ì")
        return (
            f"ì•„ë˜ SLOT{slot_id} ë‚´ìš©ì„ {rule}ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.\n"
            "- ë°˜ë“œì‹œ ì›ë¬¸ì˜ ì˜ë¯¸ë§Œ ìš”ì•½, ì¬êµ¬ì„±/ì¬í•´ì„/ìƒˆë¡œìš´ ì •ë³´ ì¶”ê°€ ê¸ˆì§€\n"
            "- SLOT{slot_id}ì˜ í•µì‹¬ ì •ë³´ë§Œ ë‚¨ê¸°ê³ , ë¬¸ì¥/ì–´íˆ¬/í†¤ì„ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”.\n"
            "- ë°˜ë“œì‹œ í•œê¸€ë¡œ, ì§€ì •ëœ ê¸€ì ìˆ˜ ë‚´ì—ì„œë§Œ ì‘ì„±í•˜ì„¸ìš”.\n"
            "- TITLE/BODYë¼ëŠ” ë‹¨ì–´ ì ˆëŒ€ ê¸ˆì§€\n"
            "\n[SLOT{slot_id}]\n"
            f"{slot_text}\n"
        )

    def _build_user_prompt_title_from_slots(self, slots_text: str) -> str:
        """
        Generate a title using only info NOT directly used in BODY, 25-40 chars, 1-2 emojis, no ì„¤ëª…ì²´/í•˜ë‹¤ì²´.
        """
        return (
            "ì•„ë˜ 4ê°œì˜ ìŠ¬ë¡¯ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì œëª©ì„ í•œê¸€ 25~40ì, ì´ëª¨ì§€ 1~2ê°œ(ì•/ë’¤ ëª¨ë‘)ì— ë§ì¶° ì‘ì„±í•˜ì„¸ìš”.\n"
            "- ë°˜ë“œì‹œ BODYì— ì§ì ‘ì ìœ¼ë¡œ ì‚¬ìš©ë˜ì§€ ì•Šì€ ì •ë³´/í¬ì¸íŠ¸ë§Œ í™œìš©\n"
            "- ì„¤ëª…ì²´, í•˜ë‹¤ì²´, '~ì´ë‹¤', '~í•©ë‹ˆë‹¤' ë“± ê¸ˆì§€\n"
            "- ì œëª©ì— TITLE/BODYë¼ëŠ” ë‹¨ì–´ëŠ” ì ˆëŒ€ ê¸ˆì§€\n"
            "- ë°˜ë“œì‹œ í•œê¸€ë¡œ, ìì—°ìŠ¤ëŸ½ê³  ëˆˆê¸¸ì„ ë„ëŠ” í‘œí˜„ë§Œ\n"
            "- ì´ëª¨ì§€ëŠ” ì œëª© ì•ë’¤ì— 1~2ê°œì”© í¬í•¨\n"
            "\n[ìŠ¬ë¡¯ ì •ë³´]\n"
            f"{slots_text}\n"
        )

    def generate(
        self,
        row: Dict[str, Any],
        plan: Dict[str, Any],
        brand_rule: Dict[str, Any],
        repair_errors: Optional[List[str]] = None,
    ) -> str:
        brand_name = self._s(row.get("brand", "ì•„ëª¨ë ˆí¼ì‹œí”½"))
        product_name = self._s(row.get("ìƒí’ˆëª…", ""))
        skin_concern = self._s(row.get("skin_concern", ""))
        lifestyle_raw = self._as_text(row.get("lifestyle", ""))
        lifestyle_phrase = self._lifestyle_phrase(lifestyle_raw)
        if not lifestyle_phrase:
            lifestyle_phrase = "ì‹¤ë‚´ í™˜ê²½ì´ ê±´ì¡°í•œ ë‚ ì—”"

        # Prepare free paragraph generation prompt
        messages = [
            {"role": "system", "content": self._build_system_prompt(brand_name)},
            {"role": "user", "content": self._build_user_prompt_free(row, plan, brand_rule)},
        ]
        raw_text = self.llm.generate(messages=messages)
        paragraph_text = raw_text["text"] if isinstance(raw_text, dict) else raw_text
        paragraph_text = self._hard_clean(paragraph_text)

        # ë¬¸ë‹¨ ë¶„ë¦¬ (ì ˆëŒ€ ìª¼ê°œê±°ë‚˜ ì¬ì‘ì„± ê¸ˆì§€)
        paragraphs = [p.strip() for p in paragraph_text.split("\n\n") if p.strip()]
        slot1 = paragraphs[0] if len(paragraphs) > 0 else ""
        slot2 = paragraphs[1] if len(paragraphs) > 1 else ""
        slot3 = paragraphs[2] if len(paragraphs) > 2 else ""
        slot4 = paragraphs[3] if len(paragraphs) > 3 else ""

        # slotë³„ ë¬¸ì¥ë¶€í˜¸/ì´ëª¨ì§€ ê·œì¹™ ê°•ì œ
        slot1 = self._enforce_slot_punct(slot1, 1)
        slot2 = self._enforce_slot_punct(slot2, 2)
        slot3 = self._enforce_slot_punct(slot3, 3)
        slot4 = self._enforce_slot_punct(slot4, 4)
        # slot4ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ê²°ë¡ ë¶€ ì§ˆë¬¸ì„ ê¸ˆì§€í•˜ë˜,
        # ì œì•ˆí˜•(ê²°ì • ìœ ë„í˜•) ì§ˆë¬¸ì€ ì¡°ê±´ë¶€ í—ˆìš©í•œë‹¤.
        slot4 = slot4.rstrip()
        if slot4.endswith("?"):
            allowed = False
            for rx in getattr(self, "slot4_allow_question_patterns", []):
                if re.search(rx, slot4):
                    allowed = True
                    break
            if not allowed:
                slot4 = slot4.rstrip("?").rstrip()

        # slot4ë§Œ pad í—ˆìš© (ìµœëŒ€ 1íšŒ)
        lines = [slot1, slot2, slot3, slot4]
        body = "\n".join(lines).strip()
        body = self._dedupe_body_ngrams(body)
        body = self._ensure_len_300_350(body)

        title_prompt = f"""
ë¸Œëœë“œ: {brand_name}
ì œí’ˆ: {product_name}
í”¼ë¶€ ê³ ë¯¼: {skin_concern}
ë¼ì´í”„ìŠ¤íƒ€ì¼: {lifestyle_phrase}

ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•´ 25~40ì ì œëª©ì„ ì‘ì„±í•˜ì„¸ìš”.
- ì´ëª¨ì§€ 1~2ê°œ í¬í•¨
- BODY ë¬¸ì¥ ì¬ì‚¬ìš© ê¸ˆì§€
- ì„¤ëª…ì²´/í•˜ë‹¤ì²´ ê¸ˆì§€
""".strip()

        title_messages = [
            {"role": "system", "content": "ì œëª©ë§Œ í•œ ì¤„ë¡œ ì‘ì„±í•˜ì„¸ìš”."},
            {"role": "user", "content": title_prompt},
        ]
        title_out = self.llm.generate(messages=title_messages)
        title = self._ensure_title_25_40_with_emojis(
            self._s(title_out.get("text", "") if isinstance(title_out, dict) else title_out),
            brand_name,
            product_name,
            skin_concern,
            lifestyle_phrase,
        )
        return f"TITLE: {title}\nBODY: {body}"
    def _has_emoji(self, s: str) -> bool:
        import re
        if not s:
            return False
        return re.search(r"[\U0001F300-\U0001FAFF]", s) is not None

    def _ensure_title_25_40_with_emojis(self, title: str, brand: str, product: str, skin_concern: str, lifestyle: str) -> str:
        title = self._s(title)
        # Remove any accidental TITLE/BODY prefixes
        title = re.sub(r"^(TITLE\s*:?\s*)", "", title, flags=re.IGNORECASE).strip()
        title = re.sub(r"^(BODY\s*:?\s*)", "", title, flags=re.IGNORECASE).strip()
        # Fallback title if too short/empty
        if len(title) < 10:
            core = f"{brand} {product}".strip()
            topic = skin_concern or "í”¼ë¶€ ì»¨ë””ì…˜"
            ctx = lifestyle or "ì˜¤ëŠ˜ ë£¨í‹´"
            title = f"{ctx} {topic}, {core}ë¡œ ì •ë¦¬í•´ìš”"
        # Enforce length range by trimming first
        if len(title) > 40:
            title = title[:40].rstrip()
        # If still shorter than 25, pad with a natural phrase (no meta)
        if len(title) < 25:
            pad = " ì´‰ì´‰í•˜ê²Œ ë§ˆë¬´ë¦¬í•´ìš”"
            title = (title + pad)[:40].rstrip()
        # Ensure emoji at both ends
        if not self._has_emoji(title[:2]):
            title = "âœ¨" + title
        if not self._has_emoji(title[-2:]):
            title = title + "âœ¨"
        # Re-trim to 40 if emoji pushed it over
        if len(title) > 40:
            title = title[:40].rstrip()
            # keep ending emoji
            if not self._has_emoji(title[-2:]):
                title = title[:-1].rstrip() + "âœ¨"
        # Ensure minimum 25 again (rare edge)
        if len(title) < 25:
            title = (title + " ì´‰ì´‰ ë£¨í‹´ì´ì—ìš”")[:40].rstrip()
            if not self._has_emoji(title[:2]):
                title = "âœ¨" + title
            if not self._has_emoji(title[-2:]):
                title = title + "âœ¨"
            if len(title) > 40:
                title = title[:40].rstrip()
        return title

    def _split_4_paragraphs(self, body: str) -> List[str]:
        lines = [ln.strip() for ln in self._s(body).split("\n") if ln.strip()]
        if len(lines) == 4:
            return lines
        # Try sentence split (simple) then group to 4
        import re
        parts = [p.strip() for p in re.split(r"[.!?â€¦]+", self._s(body)) if p.strip()]
        if len(parts) >= 4:
            return parts[:4]
        # Pad empty
        while len(lines) < 4:
            lines.append("")
        return lines[:4]

    def _validate_generated(self, title: str, body: str, brand: str, product: str) -> List[str]:
        errs: List[str] = []

        t = self._s(title)
        b = self._s(body)

        if len(t) < 25 or len(t) > 40:
            errs.append("title_len_25_40")
        if not (self._has_emoji(t[:2]) and self._has_emoji(t[-2:])):
            errs.append("title_emoji_both_sides")

        # 4 paragraphs
        lines = self._split_4lines(b)
        if len(lines) != 4:
            errs.append("slot_count_4")

        # length 300~350 (spaces included)
        if len(b) < 300 or len(b) > 350:
            errs.append("body_len_300_350")

        # must include brand/product
        if brand and brand not in b:
            errs.append("brand_missing")
        if product and product not in b:
            errs.append("product_missing")

        # ban stiff endings / ban casual ë°˜ë§ (very rough guard)
        import re
        if re.search(r"(ì´ë‹¤|í•œë‹¤|ìˆë‹¤)\.", b) or re.search(r"(ì…ë‹ˆë‹¤|í•©ë‹ˆë‹¤)\b", b):
            errs.append("speech_style_violation")
        # avoid meta banned phrases
        if self._contains_banned(b):
            errs.append("banned_phrase_detected")

        return errs
# agent10/strategy_narrator.py
import re
from typing import Any, Dict, List, Optional, Tuple


class StrategyNarrator:
    """
    - plan(message_outline) ì—†ìœ¼ë©´ generate ì‹¤í–‰ ê¸ˆì§€
    - BODYëŠ” 1:1:1:1 ìŠ¬ë¡¯(4ì¤„) ê°•ì œ: ë¼ì´í”„ìŠ¤íƒ€ì¼ â†’ ì œí’ˆ â†’ ë¼ì´í”„ìŠ¤íƒ€ì¼(ë£¨í‹´) â†’ ì¶”ê°€ ë©”ì‹œì§€(êµ¬ë§¤ í…€/ì±„ë„/í˜œíƒ)
    - BODY 300~350ì, URL ì •í™•íˆ 1íšŒ(ë§ˆì§€ë§‰), ë§ˆí¬ë‹¤ìš´ ë§í¬ ê¸ˆì§€
    - ë©”íƒ€/ê¸°íš/ì „ëµ í‘œí˜„ ê¸ˆì§€
    """

    def __init__(
        self,
        llm_client,
        pad_pool: Optional[List[str]] = None,
        tone_profile_map: Optional[Dict[str, Any]] = None,
        **kwargs,
    ):
        self.llm = llm_client
        self.tone_profile_map = tone_profile_map or {}
        self.pad_pool = pad_pool or [
            "ì˜¤ëŠ˜ ì»¨ë””ì…˜ì— ë§ì¶° ê°€ë³ê²Œ ì–¹ê¸° ì¢‹ì•„ìš”.",
            "ë¶€ë‹´ ì—†ì´ ë§¤ì¼ ì´ì–´ê°€ê¸° í¸í•´ìš”.",
            "ëˆì ì„ì´ ëœí•´ ì†ì´ ìì£¼ ê°€ìš”.",
            "ë°”ì ìˆ˜ë¡ ì§§ê²Œ ì •ë¦¬ë˜ëŠ” ë£¨í‹´ì´ í¸í•˜ì£ .",
            "ê°€ë³ê²Œ ë§ˆë¬´ë¦¬ë¼ ë‹¤ìŒ ë‹¨ê³„ê°€ ìˆ˜ì›”í•´ìš”.",
        ]

        # meta/ê¸°íš/CTA ê¸ˆì§€(ê°•ì œ)
        self.meta_ban_phrases = [
            "ë¸Œëœë“œ í†¤ì„ ìœ ì§€í•˜ë©°",
            "ë¸Œëœë“œ í†¤ì„ ì‚´ë ¤",
            "ë¸Œëœë“œ í†¤ì„ ì‚´ë¦¬",
            "ì„¤ê³„ëœ ì œí’ˆ",
            "ê¸°íšëœ",
            "ì „ëµì ìœ¼ë¡œ",
            "í†¤ì„ ë°˜ì˜í•˜ì—¬",
            "ë¸Œëœë“œ ì•„ì´ë´í‹°í‹°",
            "í´ë¦­",
            "êµ¬ë§¤í•˜ê¸°",
            "ë” ì•Œì•„ë³´ë ¤ë©´",
            "ë” ì•Œì•„ë³´ê¸°",
            "ìì„¸íˆ ë³´ê¸°",
            # ë¬¸ì œë¡œ ì§€ì ëœ ì–´ìƒ‰í•œ ì¢…ê²°ë¬¸(ì§ì ‘ ì°¨ë‹¨)
            "ì§€ì† ê°€ëŠ¥ì„± ì¸¡ë©´ì—ì„œë„ ë¶€ë‹´ ì—†ì´ ì´ì–´ê°ˆ ìˆ˜",
            "ì´ ê³¼ì •ì—ì„œ ë£¨í‹´ ë‚´ ìœ„ì¹˜, ì§€ì† ê°€ëŠ¥ì„± ì¸¡ë©´ì—ì„œë„",
            "ìˆë‹¤",
        ]
        self.meta_ban_regex = [
            r"ë¸Œëœë“œ\s*í†¤(ì„|ì´)?\s*(ìœ ì§€|ì‚´ë¦¬|ì‚´ë ¤|ë°˜ì˜)",
            r"(í´ë¦­|êµ¬ë§¤\s*í•˜ê¸°|êµ¬ë§¤í•˜ê¸°|ë”\s*ì•Œì•„\s*ë³´(ë ¤ë©´|ê¸°)|ìì„¸íˆ\s*ë³´(ê¸°|ë ¤ë©´))",
            r"(ì „ëµì |ê¸°íšëœ|ì„¤ê³„ëœ)\s*",
            r"ì§€ì†\s*ê°€ëŠ¥ì„±\s*ì¸¡ë©´",
            r"(ì´ë‹¤|ìˆë‹¤)$",
        ]

    # -------------------------
    # utils
    # -------------------------
    def _s(self, v: Any) -> str:
        return "" if v is None else str(v).strip()

    def _get_url(self, row: Dict[str, Any]) -> str:
        for k in ["url", "URL", "product_url", "productURL", "ìƒí’ˆURL", "ìƒí’ˆ_url", "link", "ë§í¬"]:
            v = self._s(row.get(k))
            if v and v.lower() != "nan":
                return v
        return ""

    def _strip_markdown_link(self, text: str) -> str:
        return re.sub(r"\[([^\]]+)\]\(https?://[^\)]+\)", r"\1", text)

    def _contains_banned(self, text: str) -> bool:
        if not text:
            return False
        for p in self.meta_ban_phrases:
            if p and p in text:
                return True
        for rx in self.meta_ban_regex:
            if re.search(rx, text):
                return True
        return False

    def _hard_clean(self, text: str) -> str:
        t = self._s(text)
        t = self._strip_markdown_link(t)
        t = re.sub(r"https?://[^\s]+", "", t, flags=re.IGNORECASE)
        t = re.sub(r"\s+", " ", t).strip()
        return t

    def _ensure_title_len(self, title: str) -> str:
        title = self._s(title)
        if len(title) <= 40:
            return title
        return title[:40].rstrip()

    def _split_4lines(self, body: str) -> List[str]:
        lines = [ln.strip() for ln in self._s(body).split("\n") if ln.strip()]
        if len(lines) >= 4:
            return lines[:4]
        parts = re.split(r"[.!?â€¦~]+", self._s(body))
        parts = [p.strip() for p in parts if p and p.strip()]
        if len(parts) >= 4:
            return parts[:4]
        while len(lines) < 4:
            lines.append("")
        if not lines[0]:
            lines[0] = self._s(body)
        return lines[:4]

    def _join_4lines(self, lines: List[str]) -> str:
        lines = [self._s(x) for x in lines[:4]]
        # 4ë¬¸ë‹¨(4ì¤„) êµ¬ì¡°ë¥¼ ê¹¨ì§€ì§€ ì•Šê²Œ ìœ ì§€ (ë¹ˆ ì¤„ë„ ë³´ì¡´)
        while len(lines) < 4:
            lines.append("")
        return "\n".join(lines[:4])

    def _fit_len_300_350(self, lines: List[str]) -> Tuple[List[str], str]:
        # 1) 4ì¤„ ê³ ì • + í´ë¦°
        lines = [self._hard_clean(x) for x in (lines[:4] if lines else [])]
        while len(lines) < 4:
            lines.append("")

        # 2) ë¹ˆ ë¬¸ë‹¨ ì±„ìš°ê¸° (4ë¬¸ë‹¨ ìœ ì§€)
        pad_pool = [self._s(x) for x in (self.pad_pool or []) if self._s(x)]
        if not pad_pool:
            pad_pool = [
                "ì˜¤ëŠ˜ ì»¨ë””ì…˜ì— ë§ì¶° ê°€ë³ê²Œ ì–¹ê¸° ì¢‹ì•„ìš”.",
                "ë¶€ë‹´ ì—†ì´ ë§¤ì¼ ì´ì–´ê°€ê¸° í¸í•´ìš”.",
                "ê°€ë³ê²Œ ë§ˆë¬´ë¦¬ë¼ ë‹¤ìŒ ë‹¨ê³„ê°€ ìˆ˜ì›”í•´ìš”.",
                "ë°”ì ìˆ˜ë¡ ì§§ê²Œ ì •ë¦¬ë˜ëŠ” ë£¨í‹´ì´ í¸í•˜ì£ .",
            ]
        pi = 0
        for i in range(4):
            if not self._s(lines[i]):
                lines[i] = pad_pool[pi % len(pad_pool)]
                pi += 1

        # 3) ê¸°ë³¸ ë°”ë”” ìƒì„± (ì¤„ë°”ê¿ˆ ìœ ì§€)
        final_body = self._join_4lines(lines).rstrip()
        final_body = re.sub(r"[\s\)\]\}.,!?:;â€¦~]+$", "", final_body)

        # 4) 300 ë¯¸ë§Œì´ë©´ 4ë²ˆì§¸ ë¬¸ë‹¨ì— padding ì¶”ê°€ (ê²°ì •ë¡ ì )
        safety = 0
        while len(final_body) < 300 and safety < 80:
            add = pad_pool[pi % len(pad_pool)]
            pi += 1
            if add and add not in lines[3]:
                lines[3] = (self._s(lines[3]) + " " + add).strip()
                lines[3] = self._hard_clean(lines[3])
                final_body = self._join_4lines(lines).rstrip()
                final_body = re.sub(r"[\s\)\]\}.,!?:;â€¦~]+$", "", final_body)
            else:
                # ì¤‘ë³µì´ë©´ ì§§ì€ ê³ ì • ë¬¸ì¥ìœ¼ë¡œ ì±„ì›€
                lines[3] = (self._s(lines[3]) + " ì˜¤ëŠ˜ë„ ê°€ë³ê²Œ ìˆ˜ë¶„ì„ ì±™ê²¨ìš”.").strip()
                lines[3] = self._hard_clean(lines[3])
                final_body = self._join_4lines(lines).rstrip()
                final_body = re.sub(r"[\s\)\]\}.,!?:;â€¦~]+$", "", final_body)
            safety += 1

        # 5) 350 ì´ˆê³¼ë©´ ê³µë°± ê²½ê³„ ê¸°ì¤€ìœ¼ë¡œ ìë¥´ë˜, 4ì¤„ êµ¬ì¡°ëŠ” ìœ ì§€
        if len(final_body) > 350:
            trimmed = final_body[:350]
            sp = trimmed.rfind(" ")
            if sp >= 280:
                trimmed = trimmed[:sp]
            trimmed = trimmed.rstrip()
            # ë§ˆì§€ë§‰ ì¤„ë¡œë§Œ ì¤„ì´ê¸° (ì• 3ì¤„ ë³´ì¡´)
            first3 = lines[:3]
            last = trimmed.split("\n")[-1].strip()
            if not last:
                last = self._s(lines[3])
            lines = [self._s(x) for x in first3] + [self._hard_clean(last)]
            final_body = self._join_4lines(lines).rstrip()
            final_body = re.sub(r"[\s\)\]\}.,!?:;â€¦~]+$", "", final_body)

            # ê·¸ë˜ë„ ê¸¸ë©´ ë§ˆì§€ë§‰ ì¤„ì„ ì¶”ê°€ë¡œ ì»·
            if len(final_body) > 350:
                # ë§ˆì§€ë§‰ ë¬¸ë‹¨ë§Œ 350ì— ë§ì¶° ì»·
                head = "\n".join([self._s(x) for x in lines[:3]]).strip()
                remain = 350 - (len(head) + 1)  # +1 for newline
                if remain < 10:
                    remain = 10
                last2 = self._s(lines[3])[:remain].rstrip()
                sp2 = last2.rfind(" ")
                if sp2 >= max(0, remain - 30):
                    last2 = last2[:sp2].rstrip()
                lines[3] = self._hard_clean(last2)
                final_body = self._join_4lines(lines).rstrip()
                final_body = re.sub(r"[\s\)\]\}.,!?:;â€¦~]+$", "", final_body)

        return lines, final_body

    def _ensure_len_300_350(self, body: str) -> str:
        """
        Compatibility wrapper.
        generate() expects _ensure_len_300_350, but legacy logic uses _fit_len_300_350.
        This method adapts the existing implementation without changing behavior.
        """
        lines = self._split_4lines(body)
        _, final_body = self._fit_len_300_350(lines)
        return final_body

    # -------------------------
    # prompt builders
    # -------------------------
    def _build_system_prompt(self, brand_name: str) -> str:
        """
        ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: í˜ë¥´ì†Œë‚˜ ì •ì˜ ë° í•µì‹¬ ê°€ì´ë“œë¼ì¸
        """
        return f"""ë‹¹ì‹ ì€ {brand_name}ì˜ ì „ë¬¸ ë§ˆì¼€íŒ… ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.
ê³ ê°ì˜ ê³ ë¯¼ì„ í•´ê²°í•˜ê³  ì œí’ˆ ì‚¬ìš©ì„ ìì—°ìŠ¤ëŸ½ê²Œ ìœ ë„í•˜ëŠ” ê°œì¸í™” ë©”ì‹œì§€ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

[í•µì‹¬ ê°€ì´ë“œ]
1. ë§íˆ¬: ì¹œê·¼í•˜ê³  ë¶€ë“œëŸ¬ìš´ 'í•´ìš”ì²´'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. (~í•©ë‹ˆë‹¤, ~í•´ìš”, ~ìˆì–´ìš” ë“±)
   - ì ˆëŒ€ ê¸ˆì§€: '~ìˆë‹¤', '~í•œë‹¤', '~í•¨' ë“±ì˜ ë”±ë”±í•œ ë¬¸ì–´ì²´ë‚˜ ì¢…ê²°ì–´ë¯¸.
2. êµ¬ì¡°: ë°˜ë“œì‹œ 4ê°œì˜ ë‹¨ë½ìœ¼ë¡œ ì¤„ë°”ê¿ˆí•˜ì—¬ êµ¬ì„±í•˜ì„¸ìš”.
   - ë‹¨ë½1: ê³µê° (ë¼ì´í”„ìŠ¤íƒ€ì¼/í™˜ê²½)
   - ë‹¨ë½2: ì œí’ˆ ì œì•ˆ (í”¼ë¶€ ê³ ë¯¼ í•´ê²°)
   - ë‹¨ë½3: ë£¨í‹´/ì‚¬ìš©ë²• (êµ¬ì²´ì ì¸ ìƒí™©)
   - ë‹¨ë½4: í˜œíƒ/ë§ˆë¬´ë¦¬ (ì§€ì† ì‚¬ìš© ìœ ë„)
3. ê¸¸ì´: ì „ì²´ ê³µë°± í¬í•¨ 300~350ìë¥¼ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì„¸ìš”.
4. í‘œí˜„: 'ë¸Œëœë“œ í†¤ì„ ìœ ì§€í•˜ë©°', 'ê¸°íšëœ', 'ì„¤ê³„ëœ' ë“±ì˜ ë©”íƒ€ ì„¤ëª…ì–´ë¥¼ ì ˆëŒ€ ì“°ì§€ ë§ˆì„¸ìš”.

[ì‘ì„± ì˜ˆì‹œ 1]
TITLE: âœ¨í™˜ì ˆê¸° ê±´ì¡°í•¨, ì„¤í™”ìˆ˜ë¡œ ë‹¤ìŠ¤ë¦¬ì„¸ìš”âœ¨
BODY: ìš”ì¦˜ì²˜ëŸ¼ ì¼êµì°¨ê°€ í° ë‚ ì”¨ì—” í”¼ë¶€ ì†ë‹¹ê¹€ì´ ë” ì‹¬í•´ì§€ì£ . ë”°ëœ»í•œ ì°¨ í•œ ì”ì²˜ëŸ¼ í”¼ë¶€ì—ë„ ê¹Šì€ ë³´ìŠµì´ í•„ìš”í•´ìš”.
ì„¤í™”ìˆ˜ ììŒìƒí¬ë¦¼ì´ ì§€ì¹œ í”¼ë¶€ì— ê¹Šì€ ì˜ì–‘ì„ ì±„ì›Œì¤„ ê±°ì˜ˆìš”.
ì„¸ì•ˆ í›„ ê¸°ì´ˆ ë§ˆì§€ë§‰ ë‹¨ê³„ì—ì„œ ë¶€ë“œëŸ½ê²Œ í´ ë°”ë¥´ë©´ ë°¤ì‚¬ì´ ì«€ì«€í•˜ê²Œ ì°¨ì˜¤ë¥´ëŠ” íƒ„ë ¥ì„ ëŠë‚„ ìˆ˜ ìˆì–´ìš”.
ê¾¸ì¤€íˆ ì‚¬ìš©í•˜ì‹œë©´ ì†ë¶€í„° ìš°ëŸ¬ë‚˜ì˜¤ëŠ” ìœ¤ê¸°ë¥¼ ê²½í—˜í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

[ì‘ì„± ì˜ˆì‹œ 2]
TITLE: ğŸ’§ë¼ë„¤ì¦ˆì™€ í•¨ê»˜ ìˆ˜ë¶„ ê°€ë“í•œ ì•„ì¹¨ì„!ğŸ’§
BODY: ë§¤ì¼ ì•„ì¹¨ í‘¸ì„í•œ í”¼ë¶€ ë•Œë¬¸ì— í™”ì¥ì´ ë“¤ëœ¨ì§€ëŠ” ì•Šìœ¼ì‹ ê°€ìš”? ìˆ˜ë¶„ ë¶€ì¡±ì€ í”¼ë¶€ ì»¨ë””ì…˜ì„ ë–¨ì–´ëœ¨ë¦¬ëŠ” ì£¼ë²”ì´ì£ .
ë¼ë„¤ì¦ˆ ì›Œí„°ë±…í¬ í¬ë¦¼ì´ ìëŠ” ë™ì•ˆ ìˆ˜ë¶„ì„ ê½‰ ì ê°€ì¤„ ê±°ì˜ˆìš”.
ì €ë… ì„¸ì•ˆ í›„ ë“¬ë¿ ë°”ë¥´ê³  ì£¼ë¬´ì‹œë©´ ë‹¤ìŒ ë‚  ì•„ì¹¨ ëª°ë¼ë³´ê²Œ ì´‰ì´‰í•´ì§„ í”¼ë¶€ê²°ì„ ë§Œë‚  ìˆ˜ ìˆì–´ìš”.
{brand_name}ì™€ í•¨ê»˜ë¼ë©´ ë§¤ì¼ ì•„ì¹¨ ìˆ˜ë¶„ìœ¼ë¡œ ê½‰ ì°¬ íˆ¬ëª…í•œ í”¼ë¶€ë¥¼ ì™„ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

[ì‘ì„± ì˜ˆì‹œ 3]
TITLE: ğŸŒ¿ì¶œê·¼ ì „ 5ë¶„, í”¼ë¶€ ê±±ì •ì—†ì´ ì‹œì‘í•˜ì„¸ìš”!ğŸ’§
BODY: ì¶œê·¼ ì „ ë°”ìœ ì•„ì¹¨, ì‚¬ë¬´ì‹¤ ì—ì–´ì»¨ê³¼ ë§ˆìŠ¤í¬ë¡œ ì†ê±´ì¡°ì™€ í”¼ì§€, ëª¨ê³µì´ ê³ ë¯¼ì´ì‹œì£ 
í”„ë¦¬ë©”ë¼ì˜ NEW ë‚˜ì´ì•„ì‹œì¹´ ìˆ˜ë”© ê¸€ë¡œìš° ì›Œí„°ë¦¬ í¬ë¦¼ 30mlê°€ ê°€ë³ê²Œ ìˆ˜ë¶„ì„ ì±„ì›Œì¤„ ê±°ì˜ˆìš”
ì„¸ì•ˆ í›„ í† ë„ˆë¡œ ì •ë¦¬í•˜ê³  ì“± ë°”ë¥´ë©´ ì•„ì¹¨/ì €ë… 3-4ë‹¨ê³„ ë£¨í‹´ì— ì‰½ê²Œ ë…¹ì•„ë“¤ì–´ìš”.
{brand_name}ì™€ í•¨ê»˜ë¼ë©´ ì‚¬ìš©ê°, ë£¨í‹´ ë‚´ ìœ„ì¹˜, ì§€ì† ê°€ëŠ¥ì„± ì¸¡ë©´ì—ì„œë„ ë¶€ë‹´ ì—†ì´ ì´ì–´ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤!
""" + f"\n- ì°¸ê³  í†¤ í‚¤ì›Œë“œ: {list(self.tone_profile_map.keys())}\n"

    def _build_user_prompt(
        self,
        row: Dict[str, Any],
        plan: Dict[str, Any],
        brand_rule: Dict[str, Any],
        repair_errors: Optional[List[str]] = None,
    ) -> str:
        brand_name = self._s(row.get("brand", ""))
        product_name = self._s(row.get("ìƒí’ˆëª…", "ì œí’ˆ"))
        
        must_include = plan.get("brand_must_include", [])
        must_str = ", ".join(must_include) if must_include else "ì—†ìŒ"

        # ë¸Œëœë“œ ê·œì¹™ ë³‘í•©
        rule_text = ""
        banned = self._s(brand_rule.get("banned", ""))
        avoid = self._s(brand_rule.get("avoid", ""))
        if banned:
            rule_text += f"- ì ˆëŒ€ ê¸ˆì§€ì–´: {banned}\n"
        if avoid:
            rule_text += f"- ì§€ì–‘í•  í‘œí˜„: {avoid}\n"

        prompt = f"""
[ê³ ê° ì •ë³´]
- ìƒí™©(Lifestyle): {plan.get('lifestyle_expanded', row.get('lifestyle', ''))}
- í”¼ë¶€ ê³ ë¯¼: {self._s(row.get('skin_concern', ''))}
- ì¶”ì²œ ì œí’ˆ: {product_name}
- í•„ìˆ˜ í¬í•¨ í‚¤ì›Œë“œ: {must_str} (ë¬¸ì¥ ì†ì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ë‚´ì„¸ìš”)
{rule_text}
[ìš”ì²­ ì‚¬í•­]
ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {brand_name}ì˜ í†¤ì•¤ë§¤ë„ˆì— ë§ëŠ” ë§¤ë ¥ì ì¸ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.
ë°˜ë“œì‹œ ì˜ˆì‹œì™€ ê°™ì€ TITLE/BODY í˜•ì‹ì„ ë”°ë¥´ì„¸ìš”.
"""
        if repair_errors:
            prompt += f"\n[ìˆ˜ì • ìš”ì²­] ì´ì „ ìƒì„± ê²°ê³¼ì— ë‹¤ìŒ ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ ë°˜ì˜í•˜ì—¬ ìˆ˜ì •í•˜ì„¸ìš”: {', '.join(repair_errors)}"

        return prompt

    def _build_user_prompt_free(
        self,
        row: Dict[str, Any],
        plan: Dict[str, Any],
        brand_rule: Dict[str, Any],
    ) -> str:
        brand_name = self._s(row.get("brand", ""))
        product_name = self._s(row.get("ìƒí’ˆëª…", "ì œí’ˆ"))

        prompt = f"""
[ì‘ì„± ì§€ì‹œ]
ì•„ë˜ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ {brand_name}ì˜ ë§ˆì¼€íŒ… ë©”ì‹œì§€ë¥¼ ììœ ë¡­ê²Œ ì‘ì„±í•˜ì„¸ìš”.

- ê¸¸ì´: ê³µë°± í¬í•¨ 600~1000ì
- êµ¬ì¡° ì œí•œ ì—†ìŒ
- ì„¤ëª…/ë¶„ì„/ìê¸°ì†Œê°œ ê¸ˆì§€
- ê³ ê°ì—ê²Œ ì§ì ‘ ë§ ê±°ëŠ” ì–´ì¡° ìœ ì§€
- ë¸Œëœë“œ/ì œí’ˆ/í”¼ë¶€ ê³ ë¯¼/ìƒí™©ì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨

[ê³ ê° ì •ë³´]
- ë¼ì´í”„ìŠ¤íƒ€ì¼: {row.get('lifestyle', '')}
- í”¼ë¶€ ê³ ë¯¼: {row.get('skin_concern', '')}
- ì¶”ì²œ ì œí’ˆ: {product_name}
"""
        return prompt

    def _build_user_prompt_rewrite(
        self,
        free_text: str,
        plan: Dict[str, Any],
    ) -> str:
        outline = plan.get("message_outline", [])
        outline_text = "\n".join([f"- {o}" for o in outline])

        prompt = f"""
[ì¬ì‘ì„± ì§€ì‹œ]
ì•„ë˜ì˜ ì›ë¬¸ì„ ì°¸ê³ í•˜ì—¬ ë§ˆì¼€íŒ… ë©”ì‹œì§€ë¥¼ ë‹¤ì‹œ ì‘ì„±í•˜ì„¸ìš”.

ìš”êµ¬ ì‚¬í•­:
1. ë°˜ë“œì‹œ TITLE/BODY í˜•ì‹
2. BODYëŠ” ì •í™•íˆ 4ê°œì˜ ë‹¨ë½ (ì¤„ë°”ê¿ˆ)
3. ë‹¨ë½ êµ¬ì¡°:
{outline_text}
4. ì „ì²´ ê¸¸ì´: ê³µë°± í¬í•¨ 300~350ì
5. ì›ë¬¸ì˜ í•µì‹¬ ì˜ë¯¸ë¥¼ ìœ ì§€í•˜ë˜ í‘œí˜„ì€ ìƒˆë¡œ ì‘ì„± (ìš”ì•½/ì¬ì§„ìˆ )
6. ì„¤ëª…ë¬¸, ìê¸°ì–¸ê¸‰, ë©”íƒ€ í‘œí˜„ ê¸ˆì§€

[ì›ë¬¸]
{free_text}
"""
        return prompt

    def generate(
        self,
        row: Dict[str, Any],
        plan: Dict[str, Any],
        brand_rule: Dict[str, Any],
        repair_errors: Optional[List[str]] = None,
    ) -> str:
        brand_name = self._s(row.get("brand", "ì•„ëª¨ë ˆí¼ì‹œí”½"))

        # --- brand_rule control ---
        brand_rule = brand_rule or {}
        banned_words = [w.strip() for w in str(brand_rule.get("banned", "")).split(",") if w.strip()]
        avoid_words = [w.strip() for w in str(brand_rule.get("avoid", "")).split(",") if w.strip()]

        # --- fields ---
        product_name = self._s(row.get("ìƒí’ˆëª…", ""))
        skin_concern = self._s(row.get("skin_concern", ""))
        lifestyle = self._s(row.get("lifestyle", ""))

        tone_rules = self._s(plan.get("tone_rules", ""))
        outline = plan.get("message_outline", [])
        outline_text = "\n".join([f"- {self._s(o)}" for o in outline if self._s(o)])

        # must include
        brand_must_include = plan.get("brand_must_include", [])
        if isinstance(brand_rule, dict):
            bri = brand_rule.get("must_include")
            if isinstance(bri, list) and bri:
                brand_must_include = bri

        must_str = ", ".join([self._s(x) for x in brand_must_include if self._s(x)]) if brand_must_include else ""

        system_p = self._build_system_prompt(brand_name)

        # --------------------------
        # Step 1) Free generation 600~1000
        # --------------------------
        free_user_p = self._build_user_prompt_free(row, plan, brand_rule)
        free_messages = [
            {"role": "system", "content": system_p},
            {"role": "user", "content": free_user_p},
        ]
        free_text = self.llm.generate(messages=free_messages)
        free_text = self._s(free_text)

        # --------------------------
        # Step 2) Rewrite to 4 slots / 300~350 with up to 8 retries
        # --------------------------
        last_errs: List[str] = []
        last_title = ""
        last_body = ""

        for attempt in range(8):
            # Build rewrite prompt using the free_text as source
            constraints = [
                "ë°˜ë“œì‹œ TITLE/BODY í˜•ì‹ì„ ì‚¬ìš©í•œë‹¤.",
                "BODYëŠ” ì¤„ë°”ê¿ˆ 4ë¬¸ë‹¨(1:1:1:1)ìœ¼ë¡œ ì‘ì„±í•œë‹¤.",
                "ë¬¸ë‹¨ ìˆœì„œ: 1) ë¼ì´í”„ìŠ¤íƒ€ì¼ 2) ì œí’ˆ/í”¼ë¶€ê³ ë¯¼ ì—°ê²° 3) ë£¨í‹´/ì‹œê°„ëŒ€ 4) ë§ˆë¬´ë¦¬ ë©”ì‹œì§€.",
                "BODY ê¸¸ì´ëŠ” ê³µë°± í¬í•¨ 300~350ìì´ë‹¤.",
                "ë°˜ë§ ê¸ˆì§€, ì„¤ëª…ìš© í•˜ë‹¤ì²´/ë¬¸ì–´ì²´(~ì´ë‹¤/~í•œë‹¤/~ìˆë‹¤, ~í•©ë‹ˆë‹¤/~ì…ë‹ˆë‹¤) ê¸ˆì§€, í•´ìš”ì²´ë¡œ ì‘ì„±í•œë‹¤.",
                "ë¸Œëœë“œëª…ê³¼ ìƒí’ˆëª…ì„ BODYì— ë°˜ë“œì‹œ í¬í•¨í•œë‹¤.",
                f"ë¸Œëœë“œ í•„ìˆ˜ í‚¤ì›Œë“œ({must_str})ëŠ” BODYì— ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•œë‹¤." if must_str else "ë¸Œëœë“œ í•„ìˆ˜ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ BODYì— ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•œë‹¤.",
                "ì¤‘ë³µ ë¬¸ì¥ ê¸ˆì§€, ë©”íƒ€/ê¸°íš/ì „ëµ ì„¤ëª… ë¬¸êµ¬ ê¸ˆì§€.",
                "TITLEì€ 25~40ì, ì œëª© ì•ë’¤ì— ê°ê° ì´ëª¨ì§€ ìµœì†Œ 1ê°œ í¬í•¨í•œë‹¤.",
                "í˜ë¥´ì†Œë‚˜ í†¤ê³¼ ë¸Œëœë“œ í†¤ì´ ëŠê»´ì§€ëŠ” ì–´íœ˜/ë¦¬ë“¬ìœ¼ë¡œ ì‘ì„±í•œë‹¤(ë©”íƒ€ í‘œí˜„ìœ¼ë¡œ ì„¤ëª…í•˜ì§€ ë§ê³  ë¬¸ì¥ ìì²´ë¡œ ë°˜ì˜).",
            ]
            if outline_text:
                constraints.append("ì•„ë˜ 4ìŠ¬ë¡¯ ê°€ì´ë“œ ë¬¸ì¥ì„ ë¬¸ì¥ ì†ì— ë…¹ì´ë˜, ë¼ë²¨ì„ ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ì§€ ì•ŠëŠ”ë‹¤:\n" + outline_text)

            repair_line = ""
            if last_errs:
                repair_line = "\n\n[ìˆ˜ì • í•„ìš”]\n- " + "\n- ".join(last_errs)

            rewrite_prompt = (
                "ë„ˆëŠ” í•œêµ­ì–´ CRM ë§ˆì¼€íŒ… ì¹´í”¼ë¼ì´í„°ë‹¤.\n\n"
                "[ì œì•½]\n- " + "\n- ".join(constraints) +
                repair_line +
                "\n\n[í•„ìˆ˜ í¬í•¨]\n"
                f"- ë¸Œëœë“œ: {brand_name}\n"
                f"- ìƒí’ˆëª…: {product_name}\n"
                + (f"- ë¸Œëœë“œ í•„ìˆ˜ í‚¤ì›Œë“œ: {must_str}\n" if must_str else "")
                + (f"- í†¤ ê·œì¹™: {tone_rules}\n" if tone_rules else "")
                + "\n[ë¸Œëœë“œ í†¤ íŒíŠ¸]\n"
                + f"- ë„ì… ë°©í–¥: {brand_rule.get('opening','')}\n"
                + f"- ë£¨í‹´ ì„¤ëª…: {brand_rule.get('routine','')}\n"
                + f"- ë§ˆë¬´ë¦¬ ë°©í–¥: {brand_rule.get('closing','')}\n"
                + "\n[ì›ë¬¸(ì°¸ê³ )]\n"
                + free_text
                + "\n"
            )

            rewrite_messages = [
                {"role": "system", "content": system_p},
                {"role": "user", "content": rewrite_prompt},
            ]
            out = self.llm.generate(messages=rewrite_messages)

            out_text = out.get("text", "") if isinstance(out, dict) else str(out)
            out_text = self._s(out_text)

            # Guard: If LLM returned empty, skip to next attempt
            if not out_text:
                last_errs = ["llm_empty_output"]
                continue

            title = "í˜œíƒ ì•ˆë‚´"
            body = out_text

            if "TITLE:" in out_text and "BODY:" in out_text:
                t_part, b_part = out_text.split("BODY:", 1)
                title = t_part.replace("TITLE:", "").strip()
                body = b_part.strip()

            # Normalize body to 4 paragraphs (hard)
            lines = self._split_4_paragraphs(body)
            # remove banned/avoid at line level
            for i in range(4):
                for bw in banned_words:
                    if bw and bw in lines[i]:
                        lines[i] = lines[i].replace(bw, "")
                for aw in avoid_words:
                    if aw and aw in lines[i]:
                        lines[i] = lines[i].replace(aw, "")
                if self._contains_banned(lines[i]):
                    for p in self.meta_ban_phrases:
                        if p:
                            lines[i] = lines[i].replace(p, "")
                    for rx in self.meta_ban_regex:
                        import re
                        lines[i] = re.sub(rx, "", lines[i])
                lines[i] = " ".join(lines[i].split()).strip()

            body = "\n".join(lines).strip()

            # Ensure must-includes (brand/product/must keywords) without breaking style
            joined = " ".join(lines)
            if brand_name and brand_name not in joined:
                lines[1] = f"{brand_name} {lines[1]}".strip()
            if product_name and product_name not in joined:
                lines[1] = f"{product_name} {lines[1]}".strip()
            if brand_must_include:
                missing = [w for w in brand_must_include if self._s(w) and self._s(w) not in " ".join(lines)]
                if missing:
                    addon = " ".join([self._s(w) for w in missing if self._s(w)])
                    lines[3] = (lines[3].rstrip() + " " + addon).strip()

            body = "\n".join([self._s(x) for x in lines]).strip()

            # Enforce final length 300~350 deterministically
            body = self._ensure_len_300_350(body)

            # Title enforcement (25~40, emoji both sides)
            title = self._ensure_title_25_40_with_emojis(title, brand_name, product_name, skin_concern, lifestyle)

            # Final hard ban check (whole body)
            if self._contains_banned(body):
                last_errs = ["banned_phrase_detected"]
                last_title, last_body = title, body
                continue

            errs = self._validate_generated(title, body, brand_name, product_name)
            if not errs:
                return f"TITLE:\n{title}\nBODY:\n{body}"

            last_errs = errs
            last_title, last_body = title, body

        # fallback (still enforce lengths)
        fb_title = self._ensure_title_25_40_with_emojis(last_title or "í”¼ë¶€ ë£¨í‹´ ì•ˆë‚´", brand_name, product_name, skin_concern, lifestyle)
        fb_body = self._ensure_len_300_350(last_body or f"{lifestyle}\n{brand_name} {product_name}\në¶€ë‹´ ì—†ì´ ì–‡ê²Œ í´ ë°œë¼ ë§ˆë¬´ë¦¬í•´ìš”\ní•„ìš”í•œ íƒ€ì´ë°ì— ê°€ë³ê²Œ ì±™ê²¨ë‘ë©´ ì¢‹ì•„ìš”")
        fb_lines = self._split_4_paragraphs(fb_body)
        fb_body = "\n".join(fb_lines).strip()
        fb_body = self._ensure_len_300_350(fb_body)

        return f"TITLE:\n{fb_title}\nBODY:\n{fb_body}"
    def _has_emoji(self, s: str) -> bool:
        import re
        if not s:
            return False
        return re.search(r"[\U0001F300-\U0001FAFF]", s) is not None

    def _ensure_title_25_40_with_emojis(self, title: str, brand: str, product: str, skin_concern: str, lifestyle: str) -> str:
        title = self._s(title)
        # Fallback title if too short/empty
        if len(title) < 10:
            core = f"{brand} {product}".strip()
            topic = skin_concern or "í”¼ë¶€ ì»¨ë””ì…˜"
            ctx = lifestyle or "ì˜¤ëŠ˜ ë£¨í‹´"
            title = f"{ctx} {topic}, {core}ë¡œ ì •ë¦¬í•´ìš”"
        # Enforce length range by trimming first
        if len(title) > 40:
            title = title[:40].rstrip()
        # If still shorter than 25, pad with a natural phrase (no meta)
        if len(title) < 25:
            pad = " ì´‰ì´‰í•˜ê²Œ ë§ˆë¬´ë¦¬í•´ìš”"
            title = (title + pad)[:40].rstrip()
        # Ensure emoji at both ends
        if not self._has_emoji(title[:2]):
            title = "âœ¨" + title
        if not self._has_emoji(title[-2:]):
            title = title + "âœ¨"
        # Re-trim to 40 if emoji pushed it over
        if len(title) > 40:
            title = title[:40].rstrip()
            # keep ending emoji
            if not self._has_emoji(title[-2:]):
                title = title[:-1].rstrip() + "âœ¨"
        # Ensure minimum 25 again (rare edge)
        if len(title) < 25:
            title = (title + " ì´‰ì´‰ ë£¨í‹´ì´ì—ìš”")[:40].rstrip()
            if not self._has_emoji(title[:2]):
                title = "âœ¨" + title
            if not self._has_emoji(title[-2:]):
                title = title + "âœ¨"
            if len(title) > 40:
                title = title[:40].rstrip()
        return title

    def _split_4_paragraphs(self, body: str) -> List[str]:
        lines = [ln.strip() for ln in self._s(body).split("\n") if ln.strip()]
        if len(lines) == 4:
            return lines
        # Try sentence split (simple) then group to 4
        import re
        parts = [p.strip() for p in re.split(r"[.!?â€¦]+", self._s(body)) if p.strip()]
        if len(parts) >= 4:
            return parts[:4]
        # Pad empty
        while len(lines) < 4:
            lines.append("")
        return lines[:4]

    def _validate_generated(self, title: str, body: str, brand: str, product: str) -> List[str]:
        errs: List[str] = []

        t = self._s(title)
        b = self._s(body)

        if len(t) < 25 or len(t) > 40:
            errs.append("title_len_25_40")
        if not (self._has_emoji(t[:2]) and self._has_emoji(t[-2:])):
            errs.append("title_emoji_both_sides")

        # 4 paragraphs
        lines = [ln for ln in b.split("\n") if ln.strip()]
        if len(lines) != 4:
            errs.append("slot_count_4")

        # length 300~350 (spaces included)
        if len(b) < 300 or len(b) > 350:
            errs.append("body_len_300_350")

        # must include brand/product
        if brand and brand not in b:
            errs.append("brand_missing")
        if product and product not in b:
            errs.append("product_missing")

        # ban stiff endings / ban casual ë°˜ë§ (very rough guard)
        import re
        if re.search(r"(ì´ë‹¤|í•œë‹¤|ìˆë‹¤)\.", b) or re.search(r"(ì…ë‹ˆë‹¤|í•©ë‹ˆë‹¤)\b", b):
            errs.append("speech_style_violation")
        # avoid meta banned phrases
        if self._contains_banned(b):
            errs.append("banned_phrase_detected")

        return errs